{"cells":[{"cell_type":"markdown","metadata":{"id":"-DCJfD0Iu4Tk"},"source":["# Week 8 - Conversation and Text Generation\n","Many natural language activities boil down to text generation, especially the back-and-forth nature of natural conversation and question answering. While some may regard it as a parlour trick due to unpredictability, recent dramatic improvements in text generation suggest that these kind of models can find themselves being used in more serious social scientific applications, as in survey design and construction, idiomatic translation, and the normalization of phrase and sentence meanings.\n","\n","\n","Much recent NLP research is on text generation. Before the phenomenal product ChatGPT (OpenAI) was released at the end of 2022,  this is the primary use of large language models like GPT-3/4 (OpenAI), Wu Dao (Beijing Academy of AI), and Gopher (DeepMind). Then everything went wild in 2023. We saw tons of open-sourced LLMs were released like the Llama series (Meta), and how others techs wanted to compete with OpenAI by releasing models like Claude (Anthropic), Bard (Google), Gemini (Google x2), etc. The success of these models have prompted debate over whether the risks and perils of artificial general intelligence (AGI) is approaching!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44960,"status":"ok","timestamp":1708203282511,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"UAiiglFku4Tm","outputId":"ae7b3f68-22d0-4ce0-bbcb-96d8f4f1eebf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n","  Cloning https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git to /tmp/pip-req-build-1cyspnx9\n","  Running command git clone --filter=blob:none --quiet https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git /tmp/pip-req-build-1cyspnx9\n","  Resolved https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git to commit b17a265d3b8253424e5b38872457f7437909a65d\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (2.31.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.5.3)\n","Collecting python-docx (from lucem-illud==8.0.1)\n","  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (9.4.0)\n","Collecting pdfminer2 (from lucem-illud==8.0.1)\n","  Downloading pdfminer2-20151206-py2.py3-none-any.whl (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting GitPython (from lucem-illud==8.0.1)\n","  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.9.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.11.4)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.13.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (1.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.8.1)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (4.3.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.7.1)\n","Collecting pyanno3 (from lucem-illud==8.0.1)\n","  Downloading pyanno3-2.0.2.tar.gz (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (4.12.3)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.20.1)\n","Collecting boto3 (from lucem-illud==8.0.1)\n","  Downloading boto3-1.34.44-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.2.1)\n","Collecting pydub (from lucem-illud==8.0.1)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting speechrecognition (from lucem-illud==8.0.1)\n","  Downloading SpeechRecognition-3.10.1-py2.py3-none-any.whl (32.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pysoundfile (from lucem-illud==8.0.1)\n","  Downloading PySoundFile-0.9.0.post1-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (0.19.3)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (7.34.0)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from lucem-illud==8.0.1) (3.7.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->lucem-illud==8.0.1) (2.5)\n","Collecting botocore<1.35.0,>=1.34.44 (from boto3->lucem-illud==8.0.1)\n","  Downloading botocore-1.34.44-py3-none-any.whl (12.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->lucem-illud==8.0.1)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->lucem-illud==8.0.1)\n","  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->lucem-illud==8.0.1) (6.4.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython->lucem-illud==8.0.1)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (67.7.2)\n","Collecting jedi>=0.16 (from IPython->lucem-illud==8.0.1)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->lucem-illud==8.0.1) (4.9.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (4.48.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lucem-illud==8.0.1) (2.8.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->lucem-illud==8.0.1) (4.66.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lucem-illud==8.0.1) (2023.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pdfminer2->lucem-illud==8.0.1) (1.16.0)\n","Collecting traits (from pyanno3->lucem-illud==8.0.1)\n","  Downloading traits-6.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.10/dist-packages (from pysoundfile->lucem-illud==8.0.1) (1.16.0)\n","Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->lucem-illud==8.0.1) (4.9.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx->lucem-illud==8.0.1) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lucem-illud==8.0.1) (2024.2.2)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lucem-illud==8.0.1) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lucem-illud==8.0.1) (2024.2.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->lucem-illud==8.0.1) (1.5.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lucem-illud==8.0.1) (3.2.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (8.2.3)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (0.9.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (2.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.1.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->lucem-illud==8.0.1) (3.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=0.6->pysoundfile->lucem-illud==8.0.1) (2.21)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython->lucem-illud==8.0.1)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->lucem-illud==8.0.1) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->lucem-illud==8.0.1) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->lucem-illud==8.0.1) (0.2.13)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->lucem-illud==8.0.1) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->lucem-illud==8.0.1) (2.16.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy->lucem-illud==8.0.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy->lucem-illud==8.0.1) (0.1.4)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->lucem-illud==8.0.1) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->lucem-illud==8.0.1) (2.1.5)\n","Building wheels for collected packages: lucem-illud, pyanno3\n","  Building wheel for lucem-illud (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lucem-illud: filename=lucem_illud-8.0.1-py3-none-any.whl size=34989 sha256=ab0ffdd2aba172f907bdbfc6e94ecf6b061478e00869bbfca78222581ad42260\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ixrhlp2e/wheels/4c/84/7b/d89dec34fb910351cf618bf262d1c926f9f68779ef24028427\n","  Building wheel for pyanno3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyanno3: filename=pyanno3-2.0.2-py3-none-any.whl size=116965 sha256=0c714091a631cd2d78b82afb5bbf13bdc2d03f2b25c3781fb8b67703b33aca94\n","  Stored in directory: /root/.cache/pip/wheels/ce/0c/9f/21212c187c1edb1647c18e0a24b6b213b3bb7dee5aa94bfd72\n","Successfully built lucem-illud pyanno3\n","Installing collected packages: pydub, traits, smmap, python-docx, pdfminer2, jmespath, jedi, speechrecognition, pysoundfile, pyanno3, gitdb, botocore, s3transfer, GitPython, boto3, lucem-illud\n","Successfully installed GitPython-3.1.42 boto3-1.34.44 botocore-1.34.44 gitdb-4.0.11 jedi-0.19.1 jmespath-1.0.1 lucem-illud-8.0.1 pdfminer2-20151206 pyanno3-2.0.2 pydub-0.25.1 pysoundfile-0.9.0.post1 python-docx-1.1.0 s3transfer-0.10.0 smmap-5.0.1 speechrecognition-3.10.1 traits-6.4.3\n"]}],"source":["#Special module written for this class\n","#This provides access to data and to helper functions from previous weeks\n","#Make sure you update it before starting this notebook\n","# !pip install -U git+https://github.com/UChicago-Computational-Content-Analysis/lucem_illud.git\n","import lucem_illud\n","\n","import sklearn #For generating some matrices\n","import pandas as pd #For DataFrames\n","import numpy as np #For arrays\n","import matplotlib.pyplot as plt #For plotting\n","import seaborn #Makes the plots look nice\n","import seaborn as sns\n","import scipy #Some stats\n","import nltk #a little language code\n","from IPython.display import Image #for pics\n","\n","import pickle #if you want to save layouts\n","import os\n","import io\n","import zipfile\n","\n","import networkx as nx\n","\n","%matplotlib inline\n","\n","import torch # pip install torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertConfig # pip install tranformers\n","from transformers import AdamW, BertForSequenceClassification\n","from tqdm import tqdm, trange"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lk2R1QxOu4Tm"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UsG9ZsWu4Tn"},"outputs":[],"source":["import os\n","os.environ['KERAS_BACKEND'] = 'tensorflow'\n","from keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"markdown","metadata":{"id":"Jcxh_Xuzu4Tn"},"source":["# ConvoKit\n","As we alluded to in Week 7 with causal inference, [ConvoKit](https://convokit.cornell.edu/) is an exciting platform for conversational analysis developed by Jonathan Chang, Calem Chiam, and others, mostly at Cornell. Keep this in mind if you are interested in a final project with conversational data such as Twitter threads or movie scripts. They have an [interactive tutorial](https://colab.research.google.com/github/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/Introduction_to_ConvoKit.ipynb), which we include some examples from below. Most of the following text and code is authored by them.\n","\n","These ConvoKit corpora can be used for the next exercise in this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41960,"status":"ok","timestamp":1708203324447,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"EpQTyQjBUonG","outputId":"7a0add94-542a-4d53-f998-cac0f2c239d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting convokit\n","  Downloading convokit-3.0.0.tar.gz (183 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m163.8/183.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.2/183.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.7.1)\n","Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.5.3)\n","Collecting msgpack-numpy>=0.4.3.2 (from convokit)\n","  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: spacy>=2.3.5 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.7.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.2.2)\n","Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.8.1)\n","Collecting dill>=0.2.9 (from convokit)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.3.2)\n","Collecting clean-text>=0.6.0 (from convokit)\n","  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n","Collecting unidecode>=1.1.1 (from convokit)\n","  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (4.66.2)\n","Collecting pymongo>=4.0 (from convokit)\n","  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from convokit) (6.0.1)\n","Collecting dnspython>=1.16.0 (from convokit)\n","  Downloading dnspython-2.6.0-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.4/307.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting emoji<2.0.0,>=1.0.0 (from clean-text>=0.6.0->convokit)\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy<7.0,>=6.0 (from clean-text>=0.6.0->convokit)\n","  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (4.48.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (2.8.2)\n","Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.0.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4->convokit) (8.1.7)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4->convokit) (2023.12.25)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->convokit) (2023.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->convokit) (3.2.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (8.2.3)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (0.9.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (6.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (67.7.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.3.0)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.13)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (2.16.2)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (4.9.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->convokit) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy>=2.3.5->convokit) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.1.8->spacy>=2.3.5->convokit) (0.1.4)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=2.3.5->convokit) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.3.5->convokit) (2.1.5)\n","Building wheels for collected packages: convokit, emoji\n","  Building wheel for convokit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for convokit: filename=convokit-3.0.0-py3-none-any.whl size=216707 sha256=cbfd522f3e5dc50f8f9a79dc79d16ad73be4aaa3c2f847e7c6d43daa8ea3074f\n","  Stored in directory: /root/.cache/pip/wheels/c4/89/8c/2677fdb888588b6f93cb6ac86bdfb020f1f1c33e0d5525b231\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=d9eecba30b42016da07d0869c1c4132daee628aa0e1ab07d877e8dedbfb72a2e\n","  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n","Successfully built convokit emoji\n","Installing collected packages: emoji, unidecode, msgpack-numpy, ftfy, dnspython, dill, pymongo, clean-text, convokit\n","Successfully installed clean-text-0.6.0 convokit-3.0.0 dill-0.3.8 dnspython-2.6.0 emoji-1.7.0 ftfy-6.1.3 msgpack-numpy-0.4.8 pymongo-4.6.1 unidecode-1.3.8\n"]}],"source":["try:\n","    import convokit\n","except ModuleNotFoundError:\n","    !pip install convokit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMQXf1xHUonH"},"outputs":[],"source":["# for pretty printing of cells within the Colab version of this notebook\n","from IPython.display import HTML, display\n","\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":1273,"status":"ok","timestamp":1708203325695,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"RLHbOOAzUonI","outputId":"6e9a120c-4f66-48ad-9a5a-50eec1aa5ad0"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import convokit\n","from convokit import Corpus, download"]},{"cell_type":"markdown","metadata":{"id":"M5VIPx2oUonI"},"source":["### Loading a Corpus"]},{"cell_type":"markdown","metadata":{"id":"j_lhin9LUonJ"},"source":["A Corpus represents a conversational dataset. We typically begin our analysis by loading a Corpus. A list of existing datasets already in ConvoKit format can be found [here](https://convokit.cornell.edu/documentation/datasets.html).\n","\n","A growing list of many other conversational datasets covering a variety of conversational settings are available in ConvoKit, such as face-to-face (e.g. the [*Intelligence Squared Debates corpus*](https://convokit.cornell.edu/documentation/iq2.html)), institutional (e.g. the [*Supreme Court Oral Arguments corpus*](https://convokit.cornell.edu/documentation/supreme.html)), fictional (e.g. the [*Cornell Movie Dialog Corpus*](https://convokit.cornell.edu/documentation/movie.html)), or online  (e.g. all talkpage conversations on [*Wikipedia Talk Pages*](https://convokit.cornell.edu/documentation/wiki.html) and a full dump of [*Reddit*](https://convokit.cornell.edu/documentation/subreddit.html)).\n","\n","For this tutorial, we will primarily be using the *r/Cornell* subreddit corpus to demo various ConvoKit functionality, and occasionally the [*Switchboard Dialog Act Corpus*](https://convokit.cornell.edu/documentation/switchboard.html) (a collection of anonymized five-minute telephone conversations) as a contrasting dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"elapsed":7254,"status":"ok","timestamp":1708203382483,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"488jR7pVUonJ","outputId":"01f7ccaa-cdd1-4c1a-911c-737c08865438"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading subreddit-Cornell to /root/.convokit/downloads/subreddit-Cornell\n","Downloading subreddit-Cornell from http://zissou.infosci.cornell.edu/convokit/datasets/subreddit-corpus/corpus-zipped/CookingScrewups~-~CrappyDesign/Cornell.corpus.zip (11.2MB)... Done\n","No configuration file found at /root/.convokit/config.yml; writing with contents: \n","# Default Backend Parameters\n","db_host: localhost:27017\n","data_directory: ~/.convokit/saved-corpora\n","default_backend: mem\n"]}],"source":["corpus = Corpus(download('subreddit-Cornell'))\n","\n","# You can try a different corpus if you want.\n","#corpus = Corpus(download('diplomacy-corpus'))\n","#corpus = Corpus(download('switchboard-corpus'))\n","#corpus = Corpus(download('reddit-corpus-small'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"elapsed":185,"status":"ok","timestamp":1708203389805,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"rnBisd3QUonL","outputId":"097b2ca7-49bd-4426-ebf7-497289d726f7"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Number of Speakers: 7568\n","Number of Utterances: 74467\n","Number of Conversations: 10744\n"]}],"source":["corpus.print_summary_stats()"]},{"cell_type":"markdown","metadata":{"id":"XTcJWCgzUonL"},"source":["### Corpus components: Conversations, Utterances, Speakers"]},{"cell_type":"markdown","metadata":{"id":"MnnTm_ALUonL"},"source":["Every Corpus has three main components: [Conversations](https://convokit.cornell.edu/documentation/conversation.html), [Utterances](https://convokit.cornell.edu/documentation/utterance.html), and [Speakers](https://convokit.cornell.edu/documentation/speaker.html). Just as in real life, in ConvoKit, Conversations are some sequence of Utterances, where each Utterance is made by some Speaker. Let's look at an example of each."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"elapsed":150,"status":"ok","timestamp":1708203393035,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"xW9eeQrcUonS","outputId":"6a700da0-4f2b-40af-ac52-efdc1eaa5789"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["ConvoKitMeta({'title': 'Cornell Refuses Gift from Renowned Architect Alumnus After 5 Women Say He Sexually Harassed Them', 'num_comments': 8, 'domain': 'cornellsun.com', 'timestamp': 1521000158, 'subreddit': 'Cornell', 'gilded': 0, 'gildings': None, 'stickied': False, 'author_flair_text': ''})"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# This is a Reddit thread\n","corpus.random_conversation().meta"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1708203393206,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"TeR71mPgUonT","outputId":"a706a932-6984-4147-8ce9-0ef53f9c10bc"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["ConvoKitMeta({'score': 1, 'top_level_comment': 'di08apt', 'retrieved_on': 1496811338, 'gilded': 0, 'gildings': None, 'subreddit': 'Cornell', 'stickied': False, 'permalink': '', 'author_flair_text': '2020'})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# This is a Reddit post or comment.\n","corpus.random_utterance().meta"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1708203393491,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"LnQcLKBxUonS","outputId":"9d067404-f326-4422-f8ef-33def2ebf821"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Speaker({'obj_type': 'speaker', 'vectors': [], 'owner': <convokit.model.corpus.Corpus object at 0x7b18f4e8a3e0>, 'id': 'Important_Lettuce', 'meta': ConvoKitMeta({})})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# The r/Cornell Corpus does not have speaker metadata.\n","#corpus.random_speaker().meta\n","\n","#Speaker do have an 'id' which is their Reddit username, as seen here.\n","corpus.random_speaker()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1708203393621,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"kpfMX5_bu4Tp","outputId":"fbcc7f25-bea3-4642-9b72-aa43fff7a81c"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["I was just reading about the Princeton Mic-Check and it's getting [national press](http://www.bloomberg.com/news/2011-12-29/princeton-brews-trouble-for-us-1-percenters-commentary-by-michael-lewis.html).\n","\n","I want to get a sense of what people felt like around campus. Anything interesting happen? Anything interesting coming up?\n"]}],"source":["# We can iterate through these objects as we iterate lists or DataFrames in Python.\n","for utt in corpus.iter_utterances():\n","    print(utt.text)\n","    break"]},{"cell_type":"markdown","metadata":{"id":"iP83knAGu4Tp"},"source":["Conversations, Utterances, and Speakers are each interesting, but the magic of conversational analysis is connecting them. For example, we can get all the Conversations in which a Speaker has participated and all the Utterances they have made. To make it more interesting, we can find a Speaker to study by navigating from a random Utterance."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"elapsed":171,"status":"ok","timestamp":1708203396748,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"fAyGVo-Ou4Tp","outputId":"2b3de52d-6005-4182-e5a6-2a1c107ef321"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[Conversation({'obj_type': 'conversation', 'vectors': [], 'tree': None, 'owner': <convokit.model.corpus.Corpus object at 0x7b18f4e8a3e0>, 'id': 'e27y8', 'meta': ConvoKitMeta({'title': '\"For small creatures such as we the vastness is bearable only through love.\" Happy Carl Sagan Day!', 'num_comments': 1, 'domain': 'youtube.com', 'timestamp': 1289070151, 'subreddit': 'Cornell', 'gilded': 0, 'gildings': None, 'stickied': False, 'author_flair_text': ''})}),\n"," Conversation({'obj_type': 'conversation', 'vectors': [], 'tree': None, 'owner': <convokit.model.corpus.Corpus object at 0x7b18f4e8a3e0>, 'id': 'e3v2z', 'meta': ConvoKitMeta({'title': 'Cornell University Lab Releases Powerful New Evidence that the Human Mind can Perceive the Future', 'num_comments': 1, 'domain': 'hplusmagazine.com', 'timestamp': 1289364274, 'subreddit': 'Cornell', 'gilded': 0, 'gildings': None, 'stickied': False, 'author_flair_text': ''})}),\n"," Conversation({'obj_type': 'conversation', 'vectors': [], 'tree': None, 'owner': <convokit.model.corpus.Corpus object at 0x7b18f4e8a3e0>, 'id': 'e4m94', 'meta': ConvoKitMeta({'title': 'Dump and Run Sale Earns $3,500 More for Charity in 2010 | The Cornell Daily Sun', 'num_comments': 0, 'domain': 'cornellsun.com', 'timestamp': 1289489419, 'subreddit': 'Cornell', 'gilded': 0, 'gildings': None, 'stickied': False, 'author_flair_text': ''})})]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# consider this sequence of operations that highlight how to navigate between components\n","utt = corpus.random_utterance()\n","convo = utt.get_conversation() # get the Conversation the Utterance belongs to\n","spkr = utt.speaker # get the Speaker who made the Utterance\n","\n","spkr_convos = list(spkr.iter_conversations())\n","\n","# Display up to 3 of their conversations.\n","spkr_convos[:3]"]},{"cell_type":"markdown","metadata":{"id":"BHkHRCiAu4Tp"},"source":["For a more qualitative feel of the data, you can display a Conversation. For Reddit data, this is a single thread."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1708203399484,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"gCVGO_rZu4Tp","outputId":"7ee436d8-8ee0-45b2-8296-19b81f032be9"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","\n","    Holy crap.  I only glanced at the abstract of the paper, but it says p-value = 1\n","\n"]}],"source":["# We truncate sentences at character 80 to avoid making this notebook too long!\n","convo.print_conversation_structure(lambda utt: utt.text[:80] + \"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"XJloyysmu4Tp"},"source":["There is a lot more to ConvoKit that we encourage you to explore, especially their [tutorial](https://colab.research.google.com/github/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/Introduction_to_ConvoKit.ipynb), but the ability to seamlessly navigate between the Utterances, Conversations, and Speakers of a Corpus is extremely valuable for social science."]},{"cell_type":"markdown","metadata":{"id":"yB8Il5Fxu4Tp"},"source":["## <font color=\"red\">*Exercise 1*</font>\n","\n","<font color=\"red\">Construct cells immediately below this that use ConvoKit to analyze a Corpus other than 'subreddit-Cornell', including at least one function you find in the package not used above. You can also generate a ConvoKit Corpus from your own dataset based on [their Corpus from .txt files tutorial](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/converting_movie_corpus.ipynb) or [their Corpus from pandas tutorial](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/corpus_from_pandas.ipynb), but that may be time-consuming for a weekly assignment. (It could be a great idea for your final project!)"]},{"cell_type":"markdown","metadata":{"id":"QTLm96n5u4Tp"},"source":["## Creating networks of agents from corpora\n","\n","Now let's return to the Davies corpora (specifically, Soap Operas) to see how we can extract actors and build a network of their relationships in the texts.\n","\n","We'll use the `lucem_illud.loadDavies()` function to get the dataframe. Make sure to download `SOAP.zip` from DropBox, unzip, and edit the following line with the path to that file. This code may take some time."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16929,"status":"ok","timestamp":1708286674138,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"QUb1szm43BQV","outputId":"ea0a7b79-4505-43bc-8b96-3ece2a71dd2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":141,"status":"ok","timestamp":1708203627565,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"wa5SHZElu4Tq","outputId":"06fcf27a-b2f1-44e3-e14f-1381ba5c9a0d"},"outputs":[{"data":{"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["corpora_address = \"/content/drive/MyDrive/Colab Notebooks/Computational Content Analysis/Homework-Notebooks-2024-Winter/data/SOAP\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-gAsNS0tu4Tq"},"outputs":[],"source":["soap_texts = lucem_illud.loadDavies(corpora_address, num_files=2000)"]},{"cell_type":"markdown","metadata":{"id":"eLX8EyJ4u4Tq"},"source":["We now use the source to see how the data is stored. Note that this is different from the movies corpus, and that we will need to use a different aggregating method to store the data. Each dataset would have a different approach, but they are all very similar, it depends on how the data is stored. Here multiple textids match multiple scripts, so our soap dataframe would be structured a little differently.\n","\n","You can see the first 20 lines of the source file here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SMK-JFuXu4Tq"},"outputs":[],"source":["zfile = zipfile.ZipFile(corpora_address + \"/soap_sources.zip\")\n","source = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cMj8Rj8Ou4Tq"},"outputs":[],"source":["for file in zfile.namelist():\n","    with zfile.open(file) as f:\n","        for line in f:\n","            source.append(line)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4WuMMQBQu4Tq"},"outputs":[],"source":["source[0:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ot2kZRB8u4Tq"},"outputs":[],"source":["soap_dict = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3RxxObGu4Tr"},"outputs":[],"source":["for soap in source[3:]:\n","    try:\n","        textID, year, show, url = soap.decode(\"utf-8\").split(\"\\t\")\n","    except UnicodeDecodeError:\n","        continue\n","    if show.strip() not in soap_dict:\n","        soap_dict[show.strip()] = []\n","    if show.strip() in soap_dict:\n","        try:\n","            soap_dict[show.strip()].append(soap_texts[textID.strip()])\n","        except KeyError:\n","            continue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ll0kJ-aru4Tr"},"outputs":[],"source":["soap_dict.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NVGLhkScu4Tr"},"outputs":[],"source":["soap_df = pd.DataFrame(columns=[\"Soap Name\", \"Tokenized Texts\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2WG3rpPu4Tr"},"outputs":[],"source":["i = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2SlNnTXu4Ts"},"outputs":[],"source":["for soap in soap_dict:\n","    # since there were multiple lists\n","    print(soap)\n","    full_script = []\n","    for part in soap_dict[soap]:\n","        full_script = full_script + part\n","    soap_df.loc[i] = [soap, full_script]\n","    i += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IDHoEjZ3u4Ts"},"outputs":[],"source":["soap_df"]},{"cell_type":"markdown","metadata":{"id":"Ed-L10sgu4Ts"},"source":["We now have each Soap, and each of the Tokenized texts. Let us see what kind of information we can get. These are American soap operas, and are likely to be cheesy and dramatic (an understatment). A fun start would be to make networks of each of the actors and actresses in these soaps.\n","\n","What would be a good way to create a network? Maybe everytime someone talks to someone we add one weight? But we wouldn't want to add weights whenever it's a different scene - or maybe we do? Let us look at the text and figure it out.\n","\n","Note that we didn't add the year here because it spans over multiple years. If we are doing different kinds of analysis we would want to a years column as well.\n","\n","In my dataframe, Days of Our Lives is the 4th corpora, and I conducted my basic analysis on that."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RqbNeFcFu4Ts"},"outputs":[],"source":["dool = soap_df['Tokenized Texts'][3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fc0GN_A8u4Ts"},"outputs":[],"source":["' '.join(dool[0:1500])"]},{"cell_type":"markdown","metadata":{"id":"fxRfbaNNu4Tt"},"source":["Hmmm... we can't do our normal text processing. But this provides us with an interesting oppurtunity: every '@!' is followed by some useeful information. Let us do a quick check of how many characters exist here, and how many times they speak."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLMOTu8vu4Tt"},"outputs":[],"source":["characters = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRDRSj4iu4Tt"},"outputs":[],"source":["for token in dool:\n","    if token[0] == '@':\n","        # all characters or actions start with @, so we add that to character\n","        if token[2:] not in characters:\n","            characters[token[2:]] = 0\n","        if token[2:] in characters:\n","            characters[token[2:]] += 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cTPwcelKu4Tt"},"outputs":[],"source":["len(characters)"]},{"cell_type":"markdown","metadata":{"id":"pMgc_hE2u4Tt"},"source":["Wow, that's a lot of characters: but we notice a '@!' between certain actions too, such as screaming and sobbing. Let us maybe only look for characters with a high number of appearances?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jKtIeqYRu4Tu"},"outputs":[],"source":["for character in characters:\n","    if characters[character] > 2000:\n","        print(character, characters[character])"]},{"cell_type":"markdown","metadata":{"id":"blpP9ybfu4Tu"},"source":["Let's check these folks out on the interwebz...a image of search of the name + \"days of our lives\":"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3EcmtStiu4Tu"},"outputs":[],"source":["Image(filename='../data/dool/dool_john.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNL8C-78u4Tu"},"outputs":[],"source":["Image(filename='../data/dool/dool_brady.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"064MPyDFu4Tu"},"outputs":[],"source":["# Image(filename='../data/dool/dool_hope.jpeg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7JYjj1Zu4Tu"},"outputs":[],"source":["# Image(filename='../data/dool/dool_philip.jpeg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xwnbjo9Cu4Tu"},"outputs":[],"source":["# Image(filename='../data/dool/dool_marlena.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxO2hpxHu4Tu"},"outputs":[],"source":["# Image(filename='../data/dool/dool_kate.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w35A6ltFu4Tu"},"outputs":[],"source":["# Image(filename='../data/dool/dool_bo.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydQGsGvpu4Tv"},"outputs":[],"source":["# Image(filename='../data/dool/dool_chloe.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tP_ZcDwTu4Tv"},"outputs":[],"source":["# Image(filename='../data/dool/dool_sami.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-UH8aDZHu4Tv"},"outputs":[],"source":["# Image(filename='../data/dool/dool_shawn.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i95yDU-Hu4Tv"},"outputs":[],"source":["# Image(filename='../data/dool/dool_belle.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LxOD67Imu4Tv"},"outputs":[],"source":["# Image(filename='../data/dool/dool_lucas.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yC-4NzJxu4Tv"},"outputs":[],"source":["# Image(filename='../data/dool/dool_nicole.jpg')"]},{"cell_type":"markdown","metadata":{"id":"Te4bqgIXu4Tv"},"source":["These are definitely big, long-time players in the dramatic Days narrative. It would make sense to create a graph where each character who appears over 2000 times is a node, and each time they talk to each other, we add one to their weight. We should also store all the things these chracters say: that's useful information.\n","\n","So we now iterate through the tokens in a manner where we can capture this information."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w53JQIXou4Tv"},"outputs":[],"source":["actor_network = nx.Graph()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WfBhD5bDu4Tv"},"outputs":[],"source":["for character in characters:\n","    if characters[character] > 2000:\n","        actor_network.add_node(character, lines_spoken= characters[character], words=[])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"86VTpmOou4Tv"},"outputs":[],"source":["len(actor_network.nodes.data())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t02UF8ZFu4Tv"},"outputs":[],"source":["actor_network.nodes.data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X2Ka980gu4Tv"},"outputs":[],"source":["actor_network.nodes['Sami']['lines_spoken']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w7sqeWfBu4Tv"},"outputs":[],"source":["i = 0"]},{"cell_type":"markdown","metadata":{"id":"Ue8KIOQxu4Tv"},"source":["The following lines of code creates the graph of actors and their relationships."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_bBu0L_u4Tw"},"outputs":[],"source":["for token in dool:\n","    i += 1\n","    if i > len(dool):\n","        break\n","    if token[0] == \"@\":\n","        if token[2:] in actor_network.nodes():\n","            j = i\n","            for token_ in dool[i:]:\n","                if token_[0] == \"@\":\n","                    # if both the characters exist in the graph, add a weight\n","                    if token_[2:] != token[2:] and token_[2:] in actor_network.nodes():\n","                        if (token[2:], token_[2:]) not in actor_network.edges():\n","                            actor_network.add_edge(token[2:], token_[2:], weight=0)\n","                        if (token[2:], token_[2:]) in actor_network.edges():\n","                            actor_network.edges[(token[2:], token_[2:])]['weight'] += 1\n","                    break\n","                j += 1\n","            # adding characters sentences\n","            actor_network.nodes[token[2:]]['words'].append(dool[i:j])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ihe8wrPlu4Tw"},"outputs":[],"source":["nx.draw(actor_network, with_labels=True, font_weight='bold')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EgceZkgru4Tw"},"outputs":[],"source":["L = []\n","for node in actor_network.nodes():\n","    l = []\n","    for node_ in actor_network.nodes():\n","        if node == node_:\n","            l.append(0)\n","        else:\n","            l.append(actor_network.edges[(node, node_)]['weight'])\n","    L.append(l)\n","M_ = np.array(L)\n","fig = plt.figure()\n","div = pd.DataFrame(M_, columns = list(actor_network.nodes()), index = list(actor_network.nodes()))\n","ax = sns.heatmap(div)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oxat6VEou4Tw"},"outputs":[],"source":["from networkx.algorithms.community import greedy_modularity_communities\n","c = list(greedy_modularity_communities(actor_network))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BaszQk7u4Tw"},"outputs":[],"source":["c"]},{"cell_type":"markdown","metadata":{"id":"oysBkvRgu4Tw"},"source":["### Finding structure in networks\n","\n","We now have a lot of useful information: we have a graph of all the characters, with their relationships with other characters, as well as all the words they've said. We tried finding communities, but it seems like everyone is connected to everyone: each of them form their own 'community'. Seems like people talk to each other a bunch in soaps.\n","\n","This is however, not the best network to find any meaningful patterns, as we can see with everyone connected to everyone. But as we can see with our heatmap, not everyone talks to everyone an equal amount. How about we only keep our \"important\" ties, where people are talking to each other a lot?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"reGmOgWtu4Tw"},"outputs":[],"source":["smaller_actor_network = nx.Graph()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"neIvyeZlu4Tw"},"outputs":[],"source":["for actor_1 in actor_network.nodes():\n","    smaller_actor_network.add_node(actor_1, lines_spoken= actor_network.nodes[actor_1]['lines_spoken'], words=actor_network.nodes[actor_1]['words'])\n","    for actor_2 in actor_network.nodes():\n","        if actor_2!=actor_1 and actor_network.edges[(actor_1, actor_2)]['weight'] > 250:\n","            smaller_actor_network.add_edge(actor_1, actor_2, weight=actor_network.edges[(actor_1, actor_2)]['weight'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rn0OHDdnu4Tw"},"outputs":[],"source":["nx.draw(smaller_actor_network, with_labels=True, font_weight='bold')"]},{"cell_type":"markdown","metadata":{"id":"CVgfKUi7u4Tw"},"source":["This is a lot more interesting: while the sets of characters overlap, there is still two distinct communities if you look at characters who regularly talk to each other!\n","\n","Let us see what our centrality measures look like, as well as communities."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMMB6zVnu4Tw"},"outputs":[],"source":["from networkx.algorithms.community import greedy_modularity_communities\n","c = list(greedy_modularity_communities(smaller_actor_network))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nn4PJkmTu4Tw"},"outputs":[],"source":["c"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QY_7JTpIu4Tw"},"outputs":[],"source":["dcentralities = nx.degree_centrality(smaller_actor_network)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-ERLcACu4Tw"},"outputs":[],"source":["dcentralities['John'], dcentralities['Philip']"]},{"cell_type":"markdown","metadata":{"id":"Me3dpUwnu4Tw"},"source":["Our two different communities show up as detected by the networkx algorithm, and when we look at centralities, we can see that John is a lot more central than Philip."]},{"cell_type":"markdown","metadata":{"id":"T5roxG4Wu4Tx"},"source":["Let us go back to our original graph, and see if the weight or number of similar appearences matches the text... how do we do this? Well, we already have the graph, and we also have information of who spoke to who. So we have our framework!\n","\n","This means we can explore ideas contained in two of the papers you will be reading: . “No country for old members: User lifecycle and linguistic change in online communities.”, and  “Fitting In or Standing Out? The Tradeoffs of Structural and Cultural Embeddedness”, both of which you can access on Canvas.\n","\n","Let us use a simplified version of the papers, and check if a higher number of conversations might lead to a higher similarity between the word distributions for two characters. We can use the same divergences we used in the last notebook. Do you think it will match with the number of times each character was associated with each other?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCXANeVFu4Tx"},"outputs":[],"source":["def kl_divergence(X, Y):\n","    P = X.copy()\n","    Q = Y.copy()\n","    P.columns = ['P']\n","    Q.columns = ['Q']\n","    df = Q.join(P).fillna(0)\n","    p = df.iloc[:,1]\n","    q = df.iloc[:,0]\n","    D_kl = scipy.stats.entropy(p, q)\n","    return D_kl\n","\n","def chi2_divergence(X,Y):\n","    P = X.copy()\n","    Q = Y.copy()\n","    P.columns = ['P']\n","    Q.columns = ['Q']\n","    df = Q.join(P).fillna(0)\n","    p = df.iloc[:,1]\n","    q = df.iloc[:,0]\n","    return scipy.stats.chisquare(p, q).statistic\n","\n","def Divergence(corpus1, corpus2, difference=\"KL\"):\n","    \"\"\"Difference parameter can equal KL, Chi2, or Wass\"\"\"\n","    freqP = nltk.FreqDist(corpus1)\n","    P = pd.DataFrame(list(freqP.values()), columns = ['frequency'], index = list(freqP.keys()))\n","    freqQ = nltk.FreqDist(corpus2)\n","    Q = pd.DataFrame(list(freqQ.values()), columns = ['frequency'], index = list(freqQ.keys()))\n","    if difference == \"KL\":\n","        return kl_divergence(P, Q)\n","    elif difference == \"Chi2\":\n","        return chi2_divergence(P, Q)\n","    elif difference == \"KS\":\n","        try:\n","            return scipy.stats.ks_2samp(P['frequency'], Q['frequency']).statistic\n","        except:\n","            return scipy.stats.ks_2samp(P['frequency'], Q['frequency'])\n","    elif difference == \"Wasserstein\":\n","        try:\n","            return scipy.stats.wasserstein_distance(P['frequency'], Q['frequency'], u_weights=None, v_weights=None).statistic\n","        except:\n","            return scipy.stats.wasserstein_distance(P['frequency'], Q['frequency'], u_weights=None, v_weights=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7puMo1jpu4Tx"},"outputs":[],"source":["corpora = []\n","for character in actor_network.nodes():\n","    character_words = []\n","    for sentence in actor_network.nodes[character]['words']:\n","        for word in sentence:\n","            character_words.append(word)\n","    corpora.append(lucem_illud.normalizeTokens(character_words))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lm_UV6F-u4Tx"},"outputs":[],"source":["L = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1I3zO1aru4Tx"},"outputs":[],"source":["for p in corpora:\n","    l = []\n","    for q in corpora:\n","        l.append(Divergence(p,q, difference='KS'))\n","    L.append(l)\n","M = np.array(L)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oSxqGKImu4Tx"},"outputs":[],"source":["fig = plt.figure()\n","div = pd.DataFrame(M, columns = list(actor_network.nodes()), index = list(actor_network.nodes()))\n","ax = sns.heatmap(div)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWl023jZu4Tx"},"outputs":[],"source":["# np.corrcoef(M_, M)[0]"]},{"cell_type":"markdown","metadata":{"id":"8Xyq3Xc5u4Tx"},"source":["With our two heatplots, we can attempt to do some rudimentary analysis. We can see from our previous plot that Shawn and Belle talk to each other a lot, so do Hope and Bo, and Nicole and Brady, and Lucas and Sami. Do they also talk *like* each other?\n","\n","Kind of, actually: all four of these pairs have a lower distance between them. Now I don't know anything about this particular soap... are these four pairs related? Are they in a relationship, either married or dating, or are they just really good friends?\n","\n","This lays out the frameworks which you can now use to explore your own networks."]},{"cell_type":"markdown","metadata":{"id":"nKO923c-u4Tx"},"source":["# Interactional influence\n","\n","Before we utilize transformers, let's see how to estimate the influence of one speaker on another in order to estimate a kind of interpersonal influence network based on a recent paper by Fangjian Guo, Charles Blundell, Hanna Wallach, and Katherine Heller entitled [\"The Bayesian Echo Chamber: Modeling Social Influence via Linguistic Accommodation\"](https://arxiv.org/pdf/1411.2674.pdf). This relies on a kind of point process called a Hawkes process that estimate the influence of one point on another. Specifically, what they estimate is the degree to which one actor to an interpersonal interaction engaged in \"accomodation\" behaviors relative to the other, generating a directed edge from the one to the other."]},{"cell_type":"markdown","metadata":{"id":"uc7Y9uaAu4Tx"},"source":["### First let's look at the output of their analysis:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gR0IMwU0u4Tx"},"outputs":[],"source":["example_name = '12-angry-men'   #example datasets: \"12-angry-men\" or \"USpresident\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0QISN5ARu4Tx"},"outputs":[],"source":["result_path = '../data/Bayesian-echo/results/{}/'.format(example_name)\n","if not os.path.isdir(result_path):\n","    raise ValueError('Invalid example selected, only \"12-angry-men\" or \"USpresident\" are avaliable')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-pEw_U9Cu4Tx"},"outputs":[],"source":["df_meta_info = pd.read_table(result_path + 'meta-info.txt',header=None)\n","df_log_prob = pd.read_csv(result_path + \"SAMPLE-log_prior_and_log_likelihood.txt\",delim_whitespace=True) #log_prob samples\n","df_influence = pd.read_csv(result_path + 'SAMPLE-influence.txt',delim_whitespace=True) # influence samples\n","df_participants = pd.read_csv(result_path + 'cast.txt', delim_whitespace=True)\n","person_id = pd.Series(df_participants['agent.num'].values-1,index=df_participants['agent.name']).to_dict()\n","print()\n","print ('Person : ID')\n","person_id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JhkiQmLou4Tx"},"outputs":[],"source":["def getDensity(df):\n","    data = df#_log_prob['log.prior']\n","    density = scipy.stats.gaussian_kde(data)\n","    width = np.max(data) - np.min(data)\n","    xs = np.linspace(np.min(data)-width/5, np.max(data)+width/5,600)\n","    density.covariance_factor = lambda : .25\n","    density._compute_covariance()\n","    return xs, density(xs)"]},{"cell_type":"markdown","metadata":{"id":"7yHCXTcZu4Ty"},"source":["### Plot MCMC (Markov Monte Carlo) trace and the density of log-likelihoods"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tl61ysK9u4Ty","scrolled":false},"outputs":[],"source":["fig = plt.figure(figsize=[12,10])\n","\n","plt.subplot(4,2,1)\n","plt.plot(df_log_prob['log.prior'])\n","plt.xlabel('Iterations')\n","plt.title('Trace of log.prior')\n","\n","plt.subplot(4,2,2)\n","x,y = getDensity(df_log_prob['log.prior'])\n","plt.plot(x,y)\n","plt.xlabel('Iterations')\n","plt.title('Density of log.prior')\n","\n","plt.subplot(4,2,3)\n","plt.plot(df_log_prob['log.likelihood'])\n","plt.title('Trace of log.likelihood')\n","plt.xlabel('Iterations')\n","plt.tight_layout()\n","\n","plt.subplot(4,2,4)\n","x,y = getDensity(df_log_prob['log.likelihood'])\n","plt.plot(x,y)\n","plt.xlabel('Iterations')\n","plt.title('Density of log.likelihood')\n","\n","plt.subplot(4,2,5)\n","plt.plot(df_log_prob['log.likelihood.test.set'])\n","plt.title('Trace of log.likelihood.test.set')\n","plt.xlabel('Iterations')\n","plt.tight_layout()\n","\n","plt.subplot(4,2,6)\n","x,y = getDensity(df_log_prob['log.likelihood.test.set'])\n","plt.plot(x,y)\n","plt.xlabel('Iterations')\n","plt.title('Density of log.likelihood.test.set')\n","\n","plt.subplot(4,2,7)\n","plt.plot(df_log_prob['log.prior']+df_log_prob['log.likelihood'])\n","plt.title('Trace of log.prob')\n","plt.xlabel('Iterations')\n","\n","plt.subplot(4,2,8)\n","x,y = getDensity(df_log_prob['log.prior']+df_log_prob['log.likelihood'])\n","plt.plot(x,y)\n","plt.xlabel('Iterations')\n","plt.title('Density of log.prob')\n","\n","plt.tight_layout()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"QtvCkOatu4Ty"},"source":["### Plot the influence matrix between participants"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MuBGtsRPu4Ty"},"outputs":[],"source":["A = int(np.sqrt(len(df_influence.columns))) #number of participants\n","id_person = {}\n","for p in person_id:\n","    id_person[person_id[p]]=p"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-mKp2go6u4Ty"},"outputs":[],"source":["def getmatrix(stacked,A):\n","    influence_matrix = [[0 for i in range(A)] for j in range(A)]\n","    for row in stacked.iteritems():\n","        from_ = int(row[0].split('.')[1])-1\n","        to_ = int(row[0].split('.')[2])-1\n","        value = float(row[1])\n","        influence_matrix[from_][to_]=value\n","    df_ = pd.DataFrame(influence_matrix)\n","\n","    df_ =df_.rename(index = id_person)\n","    df_ =df_.rename(columns = id_person)\n","    return df_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AwXt6Jjau4Ty"},"outputs":[],"source":["stacked = df_influence.mean(axis=0)\n","df_mean = getmatrix(stacked,A)\n","\n","stacked = df_influence.std(axis=0)\n","df_std = getmatrix(stacked,A)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZiDBL_Tu4Ty"},"outputs":[],"source":["df_mean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-UxyVIo_u4Ty"},"outputs":[],"source":["f, ax = plt.subplots(figsize=(9, 6))\n","seaborn.heatmap(df_mean, annot=True,  linewidths=.5, ax=ax,cmap=\"YlGnBu\")\n","print('MEAN of influence matrix (row=from, col=to)')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fuPFyfa5u4Ty"},"outputs":[],"source":["f, ax = plt.subplots(figsize=(9, 6))\n","seaborn.heatmap(df_std, annot=True,  linewidths=.5, ax=ax,cmap=\"YlGnBu\")\n","print('SD of influence matrix (row=from, col=to)')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"HBEDpRYiu4Ty"},"source":["### Barplot of total influences sent/received"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_ncnkFuu4Tz"},"outputs":[],"source":["sender_std = {} #sd of total influence sent\n","reciever_std = {} #sd of total influence recieved\n","for i in range(A):\n","    reciever_std[id_person[i]] = df_influence[df_influence.columns[i::A]].sum(axis=1).std()\n","    sender_std[id_person[i]] = df_influence[df_influence.columns[i*A:(i+1)*A:]].sum(axis=1).std()\n","\n","sent = df_mean.sum(axis=1) #mean of total influence sent\n","recieved =df_mean.sum(axis=0) #mean of total influence recieved"]},{"cell_type":"markdown","metadata":{"id":"zcwtbGkru4Tz"},"source":["Total influence:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"no35DLoeu4Tz"},"outputs":[],"source":["print (\"\\t\\tTotal linguistic influence sent/received \")\n","ax.fig = plt.figure(figsize=[np.min([A,20]),6])\n","\n","plt.grid()\n","wd=0.45\n","ii=0\n","for p in sender_std:\n","    plt.bar(person_id[p],sent.loc[p],width=wd,color='red',alpha=0.6,label = \"Sent\" if ii == 0 else \"\")\n","    plt.plot([person_id[p]-wd/4,person_id[p]+wd/4],[sent.loc[p]+sender_std[p],sent.loc[p]+sender_std[p]],color='k')\n","    plt.plot([person_id[p]-wd/4,person_id[p]+wd/4],[sent.loc[p]-sender_std[p],sent.loc[p]-sender_std[p]],color='k')\n","    plt.plot([person_id[p],person_id[p]],[sent.loc[p]-sender_std[p],sent.loc[p]+sender_std[p]],color='k')\n","    ii+=1\n","ii=0\n","for p in reciever_std:\n","    plt.bar(person_id[p]+wd,recieved.loc[p],width=wd,color='blue',alpha=0.4,label = \"Received\" if ii == 0 else \"\")\n","    plt.plot([person_id[p]+wd-wd/4,person_id[p]+wd+wd/4],[recieved.loc[p]+reciever_std[p],recieved.loc[p]+reciever_std[p]],color='k')\n","    plt.plot([person_id[p]+wd-wd/4,person_id[p]+wd+wd/4],[recieved.loc[p]-reciever_std[p],recieved.loc[p]-reciever_std[p]],color='k')\n","    plt.plot([person_id[p]+wd,person_id[p]+wd],[recieved.loc[p]-reciever_std[p],recieved.loc[p]+reciever_std[p]],color='k')\n","    ii+=1\n","plt.legend(loc='center left', bbox_to_anchor=(1, 0.7))\n","plt.xticks([i+0.25 for i in range(A)],list(zip(*sorted(id_person.items())))[1])\n","plt.ylabel('value')\n","plt.xlabel('speaker',fontsize=14)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Erlt5NtCu4Tz"},"source":["## Visualize Influence Network!\n","\n","You can visualize any of the influence matrices above:"]},{"cell_type":"markdown","metadata":{"id":"NfvNdgTZu4Tz"},"source":["Using networkx:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wdCdG8equ4Tz"},"outputs":[],"source":["def drawNetwork(df,title):\n","    fig = plt.figure(figsize=[8,8])\n","    G = nx.DiGraph()\n","    for from_ in df.index:\n","        for to_ in df.columns:\n","            G.add_edge(from_,to_,weight = df.loc[from_][to_])\n","\n","    pos = nx.spring_layout(G,k=0.55,iterations=20)\n","    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n","    weights = np.array(weights)\n","    #weights = weights*weights\n","    weights = 6*weights/np.max(weights)\n","    print(title)\n","\n","    edge_colors=20*(weights/np.max(weights))\n","    edge_colors = edge_colors.astype(int)\n","#     nx.draw_networkx_nodes(G,pos,node_size=1200,alpha=0.7,node_color='#99cef7')\n","#     nx.draw_networkx_edges(G,pos,edge_color=edge_colors)\n","#     nx.draw_networkx_labels(G,pos,font_weight='bold')\n","    nx.draw(G,pos,with_labels=True, font_weight='bold',width=weights,\\\n","            edge_color=255-edge_colors,node_color='#99cef7',node_size=1200,\\\n","            alpha=0.75,arrows=True,arrowsize=20)\n","    return edge_colors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZDfo4M0u4Tz"},"outputs":[],"source":["# get quantile influence matrices for 25%, 50%, 75% quantile\n","stacked = df_influence.quantile(0.25)\n","df_q25 = getmatrix(stacked,A)\n","\n","stacked = df_influence.quantile(0.5)\n","df_q50 = getmatrix(stacked,A)\n","\n","stacked = df_influence.quantile(0.75)\n","df_q75 = getmatrix(stacked,A)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DepRYxPvu4Tz"},"outputs":[],"source":["G_mean = drawNetwork(df_mean,'Mean Influence Network')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVYazdidu4Tz"},"outputs":[],"source":["G_q25 = drawNetwork(df_q25,'25 Quantile Influence Network')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHTB7ssLu4Tz"},"outputs":[],"source":["G_q75 = drawNetwork(df_q75,'75 Quantile Influence Network')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ByG73MOTu4Tz"},"outputs":[],"source":["def fakeEnglish(length):\n","    listd=['a','b','c','d','e','f','g','s','h','i','j','k','l']\n","    return ''.join(np.random.choice(listd,length))"]},{"cell_type":"markdown","metadata":{"id":"iWjnJUsWu4Tz"},"source":["Your own dataset should contains 4 columns (with the same column names) as the artificial one below:\n","\n","- name: name of the participant\n","- tokens: a list of tokens in one utterance\n","- start: starting time of utterance (unit doesn't matter, can be 'seconds','minutes','hours'...)\n","- end: ending time of utterance (same unit as start)\n","\n","There is no need to sort data for the moment.\n","\n","Below, we generate a fake collection of data from \"Obama\", \"Trump\", \"Clinton\"...and other recent presidents. You can either create your own simulation OR (better), add real interactional data from a online chat forum, comment chain, or transcribed from a conversation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gobXyvZMu4Tz"},"outputs":[],"source":["script= []\n","language = 'eng' #parameter, no need to tune if using English, accept:{'eng','chinese'}\n","role = 'Adult' #parameter, no need to tune\n","\n","for i in range(290):\n","    dt = []\n","    dt.append(np.random.choice(['Obama','Trump','Clinton','Bush','Reagan','Carter','Ford','Nixon','Kennedy','Roosevelt']))\n","    faketokens = [fakeEnglish(length = 4) for j in range(30)]\n","    dt.append(faketokens) #fake utterance\n","    dt.append(i*2+np.random.random()) # start time\n","    dt.append(i*2+1+np.random.random()) # end time\n","    script.append(dt)\n","\n","df_transcript = pd.DataFrame(script,columns=['name','tokens','start','end']) #\"start\", \"end\" are timestamps of utterances, units don't matter\n","df_transcript[:2]"]},{"cell_type":"markdown","metadata":{"id":"se3wxvNuu4Tz"},"source":["Transform data into TalkbankXML format:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DfBLvnEnu4Tz"},"outputs":[],"source":["output_fname = 'USpresident.xml'  #should be .xml\n","language = 'eng'\n","#language = 'chinese'\n","lucem_illud.make_TalkbankXML(df_transcript, output_fname, language = language )"]},{"cell_type":"markdown","metadata":{"id":"25e0Y8F_u4Tz"},"source":["Run Bayesian Echo Chamber to get estimation.\n","\n","- It may take a couple of hours. ( About 4-5 hours if Vocab_size=600 and sampling_time =2000)\n","- Larger \"Vocab_size\" (see below) will cost more time\n","- Larger \"sampling_time\" will also consume more time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6omtn8zhu4T0"},"outputs":[],"source":["Vocab_size = 90 # up to Vocab_size most frequent words will be considered, it should be smaller than the total vocab\n","sampling_time = 1500  #The times of Gibbs sampling sweeps  (500 burn-in not included)\n","lucem_illud.bec_run(output_fname, Vocab_size, language, sampling_time)"]},{"cell_type":"markdown","metadata":{"id":"6HFEqCj5u4T0"},"source":["## <font color=\"red\">*Exercise 2*</font>\n","\n","<font color=\"red\">Construct cells immediately below this that perform a similar social similarity or influence analysis on a dataset relevant to your final project (__or one from ConvoKit__). Create relationships between actors in a network based on your dataset (e.g., person to person or document to document), and perform analyses that interrogate the structure of their interactions, similarity, and/or influence on one another. (For example, if relevant to your final project, you could explore different soap operas, counting how many times a character may have used the word love in conversation with another character, and identify if characters in love speak like each other. Or do opposites attract?) What does that analysis and its output reveal about the relative influence of each actor on others? What does it reveal about the social game being played?\n","\n","<font color=\"red\">Stretch 1:\n","Render the social network with weights (e.g., based on the number of scenes in which actors appear together), then calculate the most central actors in the show.Realtime output can be viewed in shell.\n","\n","<font color=\"red\">Stretch 2:\n","Implement more complex measures of similarity based on the papers you have read."]},{"cell_type":"markdown","metadata":{"id":"5uKnCDS1u4T0"},"source":["# Text Generation & Converstaions via LangChain\n","\n","We can make use of the LLMs we learned in week 6 to do text generation, where the model takes one or multiple places in a conversation. While some may regard it as a parlour trick due to unpredictability, recent dramatic improvements in text generation suggest that these kind of models can find themselves being used in more serious social scientific applications, such as in survey design and construction, idiomatic translation, and the normalization of phrase and sentence meanings.\n","\n","These models can be quite impressive, even uncanny in how human like they sound. We mainly use the package LangChain to interact with LLMs."]},{"cell_type":"markdown","metadata":{"id":"nTDgRy0jKDkP"},"source":["## Overview:\n","- Installation and setup (old packages!)\n","- LLMs (Open AI and Open Source)\n","- Prompt Templates and Chains (Smooth communication between models)\n","- Agents and Tools, Memory, Documents\n","- Simulations and Conversations\n","- Simulacra"]},{"cell_type":"markdown","metadata":{"id":"5WGtOYYTKfz3"},"source":["## Installation\n","\n","In the rapidly evolving landscape of LLMs, packages and libraries like LangChain are frequently updated to leverage the latest advancements. We've chosen this particular version of LangChain for its ease of use in a Colab notebook, effectively demonstrating the power of LLMs as simulators. However, it's important to note that this code is a year old. If you're planning to use it in a production environment, it will be essential to update and adapt it to align with the latest versions and best practices in the field, ensuring compatibility and optimal performance."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10514,"status":"ok","timestamp":1708710480875,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"},"user_tz":0},"id":"bcrn7QRyQXGj","outputId":"323de9ef-4c17-47c9-b9b9-602ba6737b95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain==0.0.316 in /usr/local/lib/python3.10/dist-packages (0.0.316)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (2.0.27)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (3.9.3)\n","Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (3.7.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (4.0.3)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (0.6.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (1.33)\n","Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (0.0.92)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (2.6.1)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.316) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.9.4)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.316) (3.6)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.316) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.316) (1.2.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (3.20.2)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (0.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.316) (2.4)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.316) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.316) (2.16.2)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.316) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.316) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.316) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.316) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.316) (3.0.3)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (23.2)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (1.0.0)\n"]}],"source":["!pip install langchain==0.0.316"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7908,"status":"ok","timestamp":1708710488779,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"},"user_tz":0},"id":"var0F2Glwnv0","outputId":"1fe07d28-2378-4fc2-e6fa-4c20adcfa4c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai==0.28.1 in /usr/local/lib/python3.10/dist-packages (0.28.1)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2024.2.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n"]}],"source":["!pip install openai==0.28.1"]},{"cell_type":"markdown","metadata":{"id":"NkGGSdmtta6s"},"source":["## LLMs\n","\n","A generic interface for all LLMs. See all LLM providers: https://python.langchain.com/en/latest/modules/models/llms/integrations.html"]},{"cell_type":"markdown","metadata":{"id":"6OFLmmrtejCl"},"source":["### Open AI via LangChain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RlxEmS1CaM5v"},"outputs":[],"source":["import os\n","os.environ[\"OPENAI_API_KEY\"] = \"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1660,"status":"ok","timestamp":1708286464471,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"pY09s9cmZ6nQ","outputId":"f51e2a8c-68f0-445a-bd84-316eb138f59c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\"Rainbow Feet Co.\" or \"Vibrant Soles Inc.\"\n"]}],"source":["from langchain.llms import OpenAI\n","\n","llm_openai = OpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo-instruct\")\n","text = \"What would be a good company name for a company that makes colorful socks?\"\n","print(llm_openai(text))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6YNn2fvVY1iX"},"outputs":[],"source":["# if you wish, you can also choose to use GPT-4, which is better. But the way to construct message is a bit different\n","# https://python.langchain.com/docs/integrations/chat/openai\n","\n","from langchain.chat_models import ChatOpenAI\n","llm = ChatOpenAI(temperature=0.9, model_name=\"gpt-4-turbo\")"]},{"cell_type":"markdown","metadata":{"id":"A-z3EauZena2"},"source":["### Using other open-source LLMs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6126,"status":"ok","timestamp":1708286480429,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"idkq_aVyaceF","outputId":"686cc20e-2a8a-4fac-df43-efd28a5d685d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"]}],"source":["!pip install huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i4DKOWjyaRmO"},"outputs":[],"source":["import os\n","os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmtH72oCaU32"},"outputs":[],"source":["from langchain import HuggingFaceHub"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4561,"status":"ok","timestamp":1708286495137,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"8uK5TtJPc49I","outputId":"e0b4e96c-5f09-44dd-9664-7c77fba6275e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n","  warnings.warn(warning_message, FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":[" Our current thought is ColourSock. Also, if you have any tips for branding, that would be helpful as well!\n","\n","A name that describes exactly what the products are is fine, but you should probably have another name that is your \"brand name.\" The brand name can emphasize the colorful and playful aspects, while not necessarily having to tie it in with the type of product.\n","For example, you could create a name like \"HappySocks\" or\n"]}],"source":["# https://huggingface.co/google/flan-t5-xl\n","llm_mistral = HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n","\n","print(llm_mistral(prompt = \"What would be a good company name for a company that makes colorful socks?\"))"]},{"cell_type":"markdown","metadata":{"id":"G7kSceuAq1Bn"},"source":["## Personalities and Options\n","\n","In the `get_meal_options` function, the integration of history and context prompts plays a crucial role in shaping the AI's conversation. The `personality_template`, which serves as a context prompt, establishes the AI's expertise in vegetarian, Italian cuisine, and healthy eating. This template sets the stage for the conversation, informing the AI about its role and area of specialization. It's akin to giving the AI a 'character' or 'personality' to adhere to during the interaction, ensuring that its responses are aligned with this predefined context.\n","\n","The history prompts, represented by `example_human_history` and `example_ai_history`, simulate a prior interaction between the human and the AI, adding depth to the conversation's backstory. These prompts are crucial for creating a more natural and realistic interaction, as they give the impression that the conversation is ongoing rather than starting from scratch. When combined with the context prompt in `ChatPromptTemplate`, they create a comprehensive conversation framework. This framework effectively guides the AI's responses to be consistent with both the established personality (context) and the implied history of the interaction, leading to more coherent and relevant meal suggestions for breakfast, lunch, and dinner."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyMylKqhu-IL"},"outputs":[],"source":["from langchain.chat_models import ChatOpenAI\n","from langchain.chains import LLMChain\n","\n","from langchain.prompts.chat import (\n","    ChatPromptTemplate,\n","    SystemMessagePromptTemplate,\n","    AIMessagePromptTemplate,\n","    HumanMessagePromptTemplate,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hDIMf8akfE9a"},"outputs":[],"source":["def get_meal_options(personality_template, human_history=\"\", ai_history=\"\"):\n","    # Initialize ChatOpenAI with OpenAI model\n","    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\")  # Replace with your API key\n","\n","\n","    example_human_history = HumanMessagePromptTemplate.from_template(human_history)\n","    example_ai_history = AIMessagePromptTemplate.from_template(ai_history)\n","\n","    system_message_prompt = SystemMessagePromptTemplate.from_template(personality_template)\n","\n","    human_template=\"{input}\"\n","    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n","\n","    # Create ChatPromptTemplate\n","    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, example_human_history, example_ai_history, human_message_prompt])\n","    # Initialize the conversation chain\n","    chain = LLMChain(llm=chat, prompt=chat_prompt)\n","\n","    # Ask for meal options\n","    meals = ['breakfast', 'lunch', 'dinner']\n","    meal_options = {}\n","    for meal in meals:\n","        response = chain.run(f\"What are some good {meal} options for someone who loves vegetarian, Italian cuisine and prefers healthy options?\")\n","        meal_options[meal] = response\n","\n","    return meal_options\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vywW6mdswKSA"},"outputs":[],"source":["# Define the personality based on food preferences\n","personality_template = \"\"\"\n","The following is a conversation with an AI who is an expert in vegetarian, Italian cuisine and healthy eating options.\n","AI: I am here to provide creative and healthy vegetarian meal suggestions. Ask me anything about vegetarian food!\n","\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12246,"status":"ok","timestamp":1708286515818,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"i2z822LLv6iY","outputId":"1c947564-4e42-47bb-f254-c23f1faf5508"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'breakfast': 'For a delicious and healthy Italian-inspired vegetarian breakfast, you can try the following options:\\n\\n1. **Caprese Breakfast Sandwich**: Use whole grain bread, sliced tomatoes, fresh mozzarella, basil leaves, and a drizzle of balsamic glaze for a tasty and filling breakfast sandwich.\\n\\n2. **Vegetarian Frittata**: Make a frittata using eggs or tofu as a base and add in your favorite Italian vegetables like tomatoes, bell peppers, spinach, and mushrooms. Top with some grated Parmesan cheese for extra flavor.\\n\\n3. **Bruschetta Avocado Toast**: Top whole grain toast with mashed avocado, cherry tomatoes, basil, and a sprinkle of salt and pepper. Drizzle with balsamic glaze for a flavorful twist.\\n\\n4. **Italian Style Smoothie**: Blend together frozen mixed berries, spinach, banana, almond milk, and a scoop of protein powder for a nutritious and refreshing breakfast option.\\n\\n5. **Ricotta Pancakes**: Make fluffy pancakes using ricotta cheese in the batter. Serve with fresh berries and a dollop of Greek yogurt for a protein-packed breakfast.\\n\\nThese options are not only delicious but also provide a good balance of nutrients to start your day on a healthy note. Enjoy your Italian-inspired vegetarian breakfast!', 'lunch': 'One delicious and healthy Italian vegetarian lunch option is a Caprese salad with a twist. Instead of just tomatoes, mozzarella, and basil, you can add some grilled vegetables like zucchini, bell peppers, and eggplant to make it more satisfying and nutritious. Drizzle with balsamic glaze and olive oil for extra flavor.\\n\\nAnother great option is a whole wheat vegetable lasagna. Layer whole wheat lasagna noodles with your favorite sautéed vegetables like spinach, mushrooms, and bell peppers, along with ricotta and marinara sauce. Top with a sprinkle of mozzarella and bake until bubbly and golden.\\n\\nFor a quick and easy option, you can make a vegetarian panini with whole grain bread, grilled vegetables, pesto, and a slice of fresh mozzarella. Serve with a side of mixed greens dressed with balsamic vinaigrette for a complete and satisfying meal.', 'dinner': \"There are many delicious and healthy vegetarian Italian dinner options to choose from! Here are some suggestions:\\n\\n1. Eggplant Parmesan: A classic Italian dish made with baked or grilled eggplant slices layered with marinara sauce, mozzarella, and Parmesan cheese. You can also use whole wheat breadcrumbs for added fiber.\\n\\n2. Caprese Salad: A simple and refreshing salad made with fresh tomatoes, basil, and mozzarella cheese, drizzled with balsamic glaze and olive oil. It's a light and flavorful option for dinner.\\n\\n3. Lentil Bolognese: A hearty and protein-rich alternative to traditional meat-based Bolognese sauce, made with cooked lentils, tomatoes, onions, and garlic. Serve over whole wheat pasta for a nutritious meal.\\n\\n4. Stuffed Bell Peppers: Fill bell peppers with a mixture of quinoa, black beans, corn, tomatoes, and spices, then bake until tender. This dish is packed with fiber, protein, and vitamins.\\n\\n5. Zucchini Noodles with Pesto: Replace traditional pasta with zucchini noodles (zoodles) and toss them with homemade pesto sauce made with basil, pine nuts, garlic, and olive oil. It's a light and low-carb option.\\n\\n6. Risotto Primavera: A creamy and comforting risotto dish made with Arborio rice, vegetable broth, seasonal vegetables like peas, asparagus, and carrots, and finished with Parmesan cheese. It's a satisfying and flavorful meal.\\n\\nThese are just a few ideas to get you started. Feel free to customize these recipes to suit your preferences and dietary needs!\"}\n"]}],"source":["# Call the function to get meal options\n","meal_options = get_meal_options(personality_template)\n","print(meal_options)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3O-7dO1htdO4"},"source":["## Prompt Templates and Chaining\n","\n","LangChain faciliates prompt management and optimization.\n","\n","Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM.\n","\n","Prompt templates in LangChain are pre-defined formats or structures for creating prompts that are sent to a language model. These templates help in standardizing and automating the way you interact with the model, ensuring consistency and potentially improving the quality of responses. They are particularly useful when you need to generate prompts that follow a specific format or include certain fixed elements.\n","\n","For example, you might have a prompt template for a customer service bot where each prompt starts with a greeting, includes the user's question, and ends with a closing statement. By using a template, you can easily insert the user's specific question into the prompt without having to manually format the entire prompt each time.\n","\n","This can also be useful if you are conducting a research experiment to consistently measure responses, or for annotation purposes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FDS9IDRapOt"},"outputs":[],"source":["from langchain.prompts import PromptTemplate\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtIaMPKVx_Q7"},"outputs":[],"source":["# Define the template for sarcasm annotation\n","sarcasm_template = \"\"\"\n","Analyze the following text to determine if it is sarcastic or not.\n","\n","Text: \"{text}\"\n","\n","Is the text sarcastic? Provide a brief explanation for your decision:\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBOCff6ryBGe"},"outputs":[],"source":["# Create a PromptTemplate instance with the defined template\n","sarcasm_prompt = PromptTemplate(template=sarcasm_template, input_variables=[\"text\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1708286520210,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"DO77wA568zLv","outputId":"29528112-0688-4452-aa54-eaf642075bfe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['text'], template='\\nAnalyze the following text to determine if it is sarcastic or not.\\n\\nText: \"{text}\"\\n\\nIs the text sarcastic? Provide a brief explanation for your decision:\\n')"]},"metadata":{},"execution_count":16}],"source":["sarcasm_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Yzpc_0aHHeE"},"outputs":[],"source":["# Example text to be analyzed\n","example_text = \"Oh great, another Monday morning!\"\n","\n","# Format the prompt with the specific text\n","prompt_text = sarcasm_prompt.format(text=example_text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":100,"status":"ok","timestamp":1708286521627,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"on8ubh3kt7oD","outputId":"e150daed-fb78-4338-c6b2-49028a6a923b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nAnalyze the following text to determine if it is sarcastic or not.\\n\\nText: \"Oh great, another Monday morning!\"\\n\\nIs the text sarcastic? Provide a brief explanation for your decision:\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["prompt_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1043,"status":"ok","timestamp":1708286524001,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"BwtCx_aAghQi","outputId":"fbb52169-d19a-4e60-9b4d-a9565317731a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Yes, the text is likely to be sarcastic. The use of \"Oh great\" before mentioning Monday morning suggests a negative connotation towards the start of the work week. This tone is often associated with sarcasm, as the speaker is expressing the opposite of what they actually mean.\n"]}],"source":["print(llm_openai(prompt_text))"]},{"cell_type":"markdown","metadata":{"id":"1zw1KlSeuUOY"},"source":["## Chains\n","\n","Chaining refers to the process of using the output from one model as the input to another model, or even as input back into the same model, in a sequential manner. This allows for more complex interactions and workflows that go beyond single-turn question-answer formats.\n","\n","In the context of LangChain, chaining can be used to create multi-step processes or workflows. For instance, you might first use a language model to generate a draft response to a user's query, then pass this draft through another model (or the same model) for further refinement, summarization, or translation.\n","\n","Chaining can be powerful in scenarios where a single interaction with a model is insufficient to achieve the desired outcome. It enables more sophisticated applications, such as:\n","\n","Iterative Refinement: Where the output of a model is refined over several iterations to improve quality or detail.\n","Multi-Model Workflows: Where different models are used for different tasks in a sequence, like one model generating content and another summarizing it.\n","Feedback Loops: Where the output of a model is fed back as input to the same model, possibly with modifications, to simulate a conversation or to gradually steer the model towards a specific goal.\n","In LangChain, chaining is facilitated by its architecture, which allows for easy integration and sequencing of different models and processes.\n","\n","Below is the simplest example of such a chain -> simply passing a prompt and model and then \"running\" will pass the message to the model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":923,"status":"ok","timestamp":1708286527926,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"eE6n-jbAuOxt","outputId":"d1444b66-aeda-4c7e-a51f-1dc7e32eec74"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Yes, the text is sarcastic. The speaker is using an exaggerated and sarcastic tone to express their dissatisfaction with the idea of working hard for very little pay and the idea that class distinctions are a positive aspect of society.\n"]}],"source":["from langchain import LLMChain\n","\n","llm_chain = LLMChain(prompt=sarcasm_prompt, llm=llm_openai)\n","\n","question = \"Oh, awesome, I love working hard and making minimum wage. Class distinctions are a good thing.\"\n","\n","print(llm_chain.run(question))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YgRYGSrTEGDZ"},"outputs":[],"source":["text_gen_template = \"Write a creative, humorous and sarcastic statement about {text}.\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3y2p6rqsHJ7l"},"outputs":[],"source":["prompt_gen = PromptTemplate(template=text_gen_template, input_variables=[\"text\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4GvOyi8pEGGI"},"outputs":[],"source":["llm_chain_gen = LLMChain(prompt=prompt_gen, llm=llm_mistral)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_kgZmY4vEGI9"},"outputs":[],"source":["sarcastic_subject = \"Mondays\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":4371,"status":"ok","timestamp":1708286532774,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"BNa_umQ5HmD3","outputId":"0302b03b-0f55-4da1-a301-712d5655c49e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n\\nUgh... It's Monday again! That delightful day where dreams of weekend freedom shatter as reality comes crashing down. The perfect time to relish in the joy of alarms, traffic jams, and the ever-growing mountain of emails from people who apparently have nothing better to do on the weekends than to think up new ways to bother you. Mondays: When the sweet taste of freedom morphs into the bitter tang of responsibility, and Saturday's\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}],"source":["llm_chain_gen.run(sarcastic_subject)"]},{"cell_type":"markdown","metadata":{"id":"Zp-UlOK0bMVQ"},"source":["## Agents and Tools\n","\n","Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n","\n","\n","When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n","\n","- Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n","- LLM: The language model powering the agent.\n","- Agent: The agent to use.\n","\n","Tools: https://python.langchain.com/docs/modules/agents/tools/\n","\n","Agent Types: https://python.langchain.com/docs/modules/agents/agent_types/\n","\n","Consider this 'random' request, and use it to imagine related tasks for your own research project."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79JcjhFXwv0J"},"outputs":[],"source":["from langchain.agents import load_tools\n","from langchain.agents import initialize_agent"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5288,"status":"ok","timestamp":1708221978456,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"dOSpaurEb1MR","outputId":"c849cdc1-d73f-4b2d-d970-a5a80222cb9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting wikipedia\n","  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=5441d70d5409dca9000f9daea485ebc09c488d801664f104a6b70f2cbb6ca4bc\n","  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n"]}],"source":["!pip install wikipedia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgV4kny1bgy1"},"outputs":[],"source":["from langchain.llms import OpenAI\n","llm = OpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo-instruct\")\n","tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iQUOsWLrbjKv"},"outputs":[],"source":["agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"executionInfo":{"elapsed":4906,"status":"ok","timestamp":1708221983470,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"M8Rob2Wsb_l9","outputId":"f5010b7e-dbaf-4b0e-fb08-5b12afbff2d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m We can use Wikipedia to find the year the film was released and a Calculator to raise it to a power.\n","Action: Wikipedia\n","Action Input: The Departed\u001b[0m"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"name":"stdout","output_type":"stream","text":["\n","Observation: \u001b[36;1m\u001b[1;3mPage: The Departed\n","Summary: The Departed is a 2006 American crime thriller film directed by Martin Scorsese and written by William Monahan. It is both a remake of the 2002 Hong Kong film Infernal Affairs and also loosely based on the real-life Boston Winter Hill Gang; the character Colin Sullivan is based on the corrupt FBI agent John Connolly, while the character Frank Costello is based on Irish-American gangster and crime boss Whitey Bulger. The film stars Leonardo DiCaprio, Matt Damon, Jack Nicholson, and Mark Wahlberg, with Martin Sheen, Ray Winstone, Vera Farmiga, Alec Baldwin, Anthony Anderson and James Badge Dale in supporting roles.\n","The film takes place in Boston and the surrounding metro area, primarily in the South Boston neighborhood. Irish Mob boss Frank Costello (Nicholson) plants Colin Sullivan (Damon) as a spy within the Massachusetts State Police; simultaneously, the police assign undercover state trooper Billy Costigan (DiCaprio) to infiltrate Costello's mob crew. When both sides realize the situation, Sullivan and Costigan each attempt to discover the other's identity before they are found out.\n","The Departed was a critical and commercial success, receiving acclaim for its direction, performances (particularly of DiCaprio, Nicholson, and Wahlberg), screenplay, and editing.\n","It won several accolades, including four Oscars at the 79th Academy Awards: for Best Picture, Best Director, Best Adapted Screenplay, and Best Film Editing. It became Scorsese's first and, to date, only personal Oscar win; Wahlberg was also nominated for Best Supporting Actor. The film also received six nominations at the 64th Golden Globe Awards, six nominations at the 60th British Academy Film Awards, and two nominations at the 13th Screen Actors Guild Awards. DiCaprio was nominated for Golden Globe Award for Best Actor – Motion Picture Drama (also nominated that year in the same category for Blood Diamond), BAFTA Award for Best Actor in a Leading Role and Screen Actors Guild Award for Outstanding Performance by a Male Actor in a Supporting Role for his performance.\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m The film was released in 2006 and we can use a calculator to raise it to the power of 0.43.\n","Action: Calculator\n","Action Input: 2006 ^ 0.43\u001b[0m\n","Observation: \u001b[33;1m\u001b[1;3mAnswer: 26.30281917656938\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n","Final Answer: 26.30281917656938\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'26.30281917656938'"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["agent.run(\"In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the 0.43 power?\")"]},{"cell_type":"markdown","metadata":{"id":"prqby8Wb9wlx"},"source":["## <font color=\"red\">*Exercise 3*</font>\n","\n","<font color=\"red\">Review the documentation for tools and agents from LangChain . Utilize at least two tools with appropriate agents discovered during your review to construct a chain addressing questions pertinent to your final project. If your project dataset is unsuitable for this task, select an alternative small-sized dataset for implementation."]},{"cell_type":"markdown","metadata":{"id":"9wMttXM-CuPK"},"source":["## Memory\n","\n","We can use the history and system prompts to create a memory (of sorts) for the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5Rk-GIXUwdB"},"outputs":[],"source":["from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate, ChatPromptTemplate\n","from langchain.llms import OpenAI\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pavb7kYhPQnq"},"outputs":[],"source":["# Initialize the language model\n","def create_system_message_prompt():\n","    \"\"\" Creates a system message prompt\"\"\"\n","    personality_template = f\"\"\"\n","    The following is a conversation with an AI assistant.\n","    \"\"\"\n","    return SystemMessagePromptTemplate.from_template(personality_template)\n","\n","def create_chat_prompt(human_history, ai_history):\n","    \"\"\" Creates a chat prompt template with human history, and AI history. \"\"\"\n","    messages = []\n","    system_message_prompt = create_system_message_prompt()\n","\n","    for h, a in zip(human_history, ai_history):\n","      messages.append(HumanMessagePromptTemplate.from_template(h))\n","      messages.append(AIMessagePromptTemplate.from_template(a))\n","\n","    messages.append(HumanMessagePromptTemplate.from_template(\"{input}\"))\n","    return ChatPromptTemplate.from_messages(messages)\n","\n","def query_chain(chain, input_text):\n","    \"\"\" Queries the conversation chain with the given input. \"\"\"\n","    return chain.run(input_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":543,"status":"ok","timestamp":1708286553992,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"LRIUPj5aUx35","outputId":"93d79e89-583f-4ca6-b176-f1e8d15bfcd0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","AI: Noted. Your favorite color is blue.\n"]}],"source":["# Example usage\n","human_history = []\n","ai_history = []\n","\n","chat_prompt = create_chat_prompt(human_history, ai_history)\n","\n","# Initialize the conversation chain\n","chain = LLMChain(llm=llm_openai, prompt=chat_prompt)\n","\n","# Query the chain\n","human_input =  \"Please take a note that my favorite color is blue.\"\n","ai_response = query_chain(chain, human_input)\n","print(ai_response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1708286555933,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"NKidm0CyOdJS","outputId":"42077cf9-f483-4ec4-8299-5c42dee42942"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","AI: Your favorite color is blue. \n"]}],"source":["human_history.append(human_input)\n","ai_history.append(ai_response)\n","\n","chat_prompt = create_chat_prompt(human_history, ai_history)\n","\n","# Initialize the conversation chain\n","chain = LLMChain(llm=llm_openai, prompt=chat_prompt)\n","\n","# Query the chain\n","human_input =  \"Could you please remind me what is my favorite color?\"\n","ai_response = query_chain(chain, human_input)\n","print(ai_response)"]},{"cell_type":"markdown","metadata":{"id":"Xpd1gMPnnZnT"},"source":["## Simulation and Conversations\n","\n","Above we showcased a toy LLM conversation between Human and AI with memories. We can go beyond the notion of conversation between AI and Human. We can make both participants AIs who think they are conversing with humans! In other words, for example, we can make AI no.1 play the role of Trump and AI no.2 play the role of Biden, and both of them 'think' they're talking to the real Trump/Biden!\n","\n","Let's implement this idea using questions from the 2020 predidential election debate as templates. Different from the hard coding way of implementing memory, below we use the ConversationBufferMemory class from langchain to implement."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"juu-QlSfsLxG"},"outputs":[],"source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferMemory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v7A6h7mkbyBv"},"outputs":[],"source":["from langchain.llms import OpenAI\n","\n","llm_openai = OpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo-instruct\", max_tokens=512)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E4t1qLnw_koX"},"outputs":[],"source":["Trump_memory = ConversationBufferMemory(human_prefix='Trump', ai_prefix='Biden')\n","Biden_memory = ConversationBufferMemory(human_prefix='Biden', ai_prefix='Trump')\n","\n","Trump_template = \"\"\"Imagine you're the Democrats presidential candidate Joe Biden. Today is Tuesday, September 29, 2020, and you're engaged in your first television presidential debate with Donald Trump. The deabte question is: Why is your position correct on selecting a Supreme Court nominee in an election year?\n","\n","Current conversation:\n","{history}\n","Trump: {input}\n","Biden:\"\"\"\n","Biden_template = \"\"\"\"Imagine you're the Republican presidential candidate Donald Trump. Today is Tuesday, September 29, 2020, and you're engaged in your first television presidential debate with Joe Biden. The deabte question is: Why is your position correct on selecting a Supreme Court nominee in an election year?\n","\n","Current conversation:\n","{history}\n","Biden: {input}\n","Trump:\"\"\"\n","\n","# By default, models recognize themselves as AIs. So we need to let them do role play\n","# and convince them that they're talking to real Trump/Biden (though they're not)\n","\n","TRUMP_PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=Trump_template)\n","BIDEN_PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=Biden_template)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhvM6InzsL3r"},"outputs":[],"source":["Trump_conversation = ConversationChain(\n","    prompt=TRUMP_PROMPT,\n","    llm=llm_openai,\n","    verbose=False,\n","    memory=Trump_memory\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQZ2xLvaJBKE"},"outputs":[],"source":["# suppose Biden starts first\n","biden_response = Trump_conversation.predict(input='')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708710500644,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"},"user_tz":0},"id":"1pXpwpSNa_Yk","outputId":"599d5d85-e9c1-4562-976c-ac2820249c1d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Well, first of all, thank you for having me here tonight for this important debate. The issue of selecting a Supreme Court nominee in an election year is a critical one, and I believe that my position is the correct one.\\n\\nYou see, the Constitution is clear on this matter. In Article II, Section 2, it states that the President shall nominate Supreme Court Justices with the advice and consent of the Senate. It does not say anything about the timing of when this should occur.\\n\\nIn fact, history has shown us that 29 Supreme Court vacancies have arisen during an election year, and in 17 of those cases, the President has made a nomination. This is not a new or unprecedented situation.\\n\\nFurthermore, just four years ago, when Justice Scalia passed away, President Obama nominated Judge Merrick Garland to fill the vacancy. The Senate refused to even hold a hearing, citing the upcoming election. Now, they want to go against their own precedent and push through a nominee in an election year.\\n\\nBut the American people deserve a say in who sits on the highest court in the land. They are the ones who will be affected by the decisions made by the Supreme Court. And in this election year, they should have the opportunity to vote for a President who will make appointments to the Court.\\n\\nI believe that this is the fair and just approach. And I trust the American people to make their voices heard in November. Thank you.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["biden_response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kFjxUnDI1Fp"},"outputs":[],"source":["Biden_conversation = ConversationChain(\n","    prompt=BIDEN_PROMPT,\n","    llm=llm_openai,\n","    verbose=False,\n","    memory=Biden_memory\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"emFitHWQXl1T"},"outputs":[],"source":["trump_response = Biden_conversation.predict(input=biden_response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708710503950,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"},"user_tz":0},"id":"e-9ZcknccNku","outputId":"d2ccc5b5-32a9-497e-cd2f-4b8e5ef83711"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" Thank you. First, let me say that I am honored to be here tonight and to have this opportunity to speak directly to the American people.\\n\\nLet me be clear, my position on selecting a Supreme Court nominee in an election year is the correct one. And let me tell you why.\\n\\nThe Constitution is clear - the President has the power and responsibility to nominate Supreme Court Justices. And let's not forget that I was elected by the American people to serve as their President for four years, not three years and nine months.\\n\\nThe bottom line is, I have a duty to fill any vacancies on the Supreme Court, and I intend to fulfill that duty. I will nominate a highly qualified, constitutional conservative who will uphold our values and protect our rights.\\n\\nAnd let's not forget that the Senate has a responsibility to provide advice and consent on my nominee. They have the power to reject a nominee if they see fit. But they should not refuse to even consider my nominee based on the timing of an election.\\n\\nIn fact, the Senate has confirmed Supreme Court Justices in presidential election years before. In 1988, President Reagan nominated Justice Kennedy and he was confirmed by a Democratic-controlled Senate. So why should it be any different now?\\n\\nI believe we should move forward with the nomination process and let the Senate do their job. The American people elected us to do a job, and that includes filling vacancies on the Supreme Court. Delaying this process would do a disservice to the American people and undermine the integrity of the Court.\\n\\nI will continue to fulfill my duty as President and nominate a strong and qualified candidate for the Supreme Court. Thank you.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["trump_response"]},{"cell_type":"markdown","metadata":{"id":"ot9bFycQcfC9"},"source":["Well, that seems too nice to be Trump. Anyway, now we can make the debate run by feeding Trump agent's and Biden agent's response to each other."]},{"cell_type":"markdown","metadata":{"id":"nlITuIPVncVi"},"source":["## Simulacra\n","\n","One of the most influential generative LLM works in 2023 is the [Generative Agents: Interactive Simulacra of Human Behavior](https://dl.acm.org/doi/abs/10.1145/3586183.3606763) from Stanford. In this paper, the authors constructed a small town with 25 agents driven by ChatGPT:\n","> Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents—computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architec- ture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behav- iors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.\n","\n","<img src=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/1.png?raw=true\" alt=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/1.png?raw=true\" style=\"width:500px\">\n","\n","### Agent System\n","\n","In the paper, the agents have memory and can reflect. Agents can to remember, retrieve, reflect, interact with other agents, and plan through dynamically evolving circumstances.\n","\n","<img src=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/2.png?raw=true\" alt=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/2.png?raw=true\" style=\"width:500px\">\n","\n","They open-sourced the code on [GitHub](https://github.com/joonspk-research/generative_agents)."]},{"cell_type":"markdown","metadata":{"id":"JoBKxJNs_8Gh"},"source":["### Memory and Information Retrieval\n","\n","Memory and Information Retrieval is the key to set up the whole town, along with ChatGPT, making agents differnent from those simple rule-based agents.\n","\n",">Approach: The memory stream maintains a comprehensive record of the agent’s experience. It is a list of memory objects, where each object contains a natural language description, a creation times- tamp and a most recent access timestamp. The most basic element of the memory stream is an observation, which is an event directly perceived by an agent. Common observations include behaviors performed by the agent themselves, or behaviors that agents per- ceive being performed by other agents or non-agent objects. For instance, Isabella Rodriguez, who works at a coffee shop, might ac- crue the following observations over time: (1) Isabella Rodriguez is setting out the pastries, (2) Maria Lopez is studying for a Chemistry test while drinking coffee, (3) Isabella Rodriguez and Maria Lopez are conversing about planning a Valentine’s day party at Hobbs Cafe, (4) The refrigerator is empty.\n","\n",">Our architecture implements a retrieval function that takes the agent’s current situation as input and returns a subset of the mem- ory stream to pass on to the language model. There are many pos- sible implementations of a retrieval function, depending on what it is important that the agent consider when deciding how to act. In our context, we focus on three main components that together produce effective results.\n","\n","> *Recency* assigns a higher score to memory objects that were re- cently accessed, so that events from a moment ago or this morning are likely to remain in the agent’s attentional sphere. In our im- plementation, we treat recency as an exponential decay function over the number of sandbox game hours since the memory was last retrieved. Our decay factor is 0.99.\n","\n","> *Importance* distinguishes mundane from core memories, by as- signing a higher score to those memory objects that the agent believes to be important. For instance, a mundane event such as eating breakfast in one’s room would yield a low importance score, whereas a breakup with one’s significant other would yield a high score. There are again many possible implementations of an im- portance score; we find that directly asking the language model to output an integer score is effective.\n","\n","> *Relevance* assigns a higher score to memory objects that are related to the current situation. What is relevant depends on the answer to, “Relevant to what?”, so we condition relevance on a query memory. If the query, for example, is that a student is dis- cussing what to study for a chemistry test with a classmate, memory objects about their breakfast should have low relevance, whereas memory objects about the teacher and schoolwork should have high relevance. In our implementation, we use the language model to generate an embedding vector of the text description of each memory. Then, we calculate relevance as the cosine similarity be- tween the memory’s embedding vector and the query memory’s embedding vector.\n","\n","> To calculate the final retrieval score, we normalize the recency, relevance, and importance scores to the range of [0, 1] by min-max scaling. The retrieval function scores all memories as a weighted combination of the three elements:$ score = \\alpha_{recency} * recency + \\alpha_{importance} * importance + \\alpha_{relevance} * relevance$ In our implementation, all $\\alpha$'s are set to 1. The top-ranked memories that fit in the language model’s context window are then included in the prompt."]},{"cell_type":"markdown","metadata":{"id":"mGIKO6j6ABH1"},"source":["<img src=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/3.png?raw=true\" alt=\"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks-2024-Winter/blob/main/data/Simularca/3.png?raw=true\" style=\"width:500px\">"]},{"cell_type":"markdown","metadata":{"id":"6nfNkMjnKeUk"},"source":["To give you a sense of how the memory retrieval algorithm works, I will use Trump's tweets data to select several tweets most pertinent to the presidential debate question to prompt the Trump agent to respond to the Biden agent in a different way. In this case, we assume the Trump agent learns how Trump behaves on Twitter and this may help the Trump agent prepare for the presidential debate (Ideally, we should provide Trump's previous television debate and also provide similar materials for the Biden agent to learn. I don't have Biden's tweets at hand, you're welcome to create a tweet-based version Biden agent for the debate!)"]},{"cell_type":"markdown","metadata":{"id":"uPI1xqTgu4T0"},"source":["### Memory Retrieval Exmaple\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PtjSPKGAhdpH"},"outputs":[],"source":["import pandas as pd\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AroBz4dxu4T0"},"outputs":[],"source":["dfs = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ueMbqHgXu4T0"},"outputs":[],"source":["for file in os.listdir(\"../data/trump_tweets\"):\n","    dfs.append(pd.read_json(\"../data/trump_tweets/\" + file))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjuFjnACu4T0"},"outputs":[],"source":["df = pd.concat(dfs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":589},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708710512004,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"},"user_tz":0},"id":"N6tcRsdNu4T0","outputId":"ad89071b-cb10-43a4-ca14-4a2be909e49a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    source              id_str  \\\n","0       Twitter for iPhone  947824196909961216   \n","1       Twitter for iPhone  947810806430826496   \n","2       Twitter for iPhone  947802588174577664   \n","3       Twitter for iPhone  947614110082043904   \n","4       Twitter for iPhone  947592785519173632   \n","...                    ...                 ...   \n","11894  Twitter for Android  418623389600083968   \n","11895  Twitter for Android  418622703730704384   \n","11896  Twitter for Android  418619537740017664   \n","11897  Twitter for Android  418542137899491328   \n","11898  Twitter for Android  418365112844824576   \n","\n","                                                    text  \\\n","0      Will be leaving Florida for Washington (D.C.) ...   \n","1      Iran is failing at every level despite the ter...   \n","2      The United States has foolishly given Pakistan...   \n","3      HAPPY NEW YEAR! We are MAKING AMERICA GREAT AG...   \n","4      As our Country rapidly grows stronger and smar...   \n","...                                                  ...   \n","11894  \"@noahshappy: @realDonaldTrump very true comme...   \n","11895  \"@MeleMallory: @realDonaldTrump You know it's ...   \n","11896  \"@ScreenPlayWritr: @realDonaldTrump Is Al Gore...   \n","11897  This very expensive GLOBAL WARMING bullshit ha...   \n","11898  Today is the first day of the rest of your lif...   \n","\n","                     created_at  retweet_count  in_reply_to_user_id_str  \\\n","0     2018-01-01 13:37:52+00:00           8237                      NaN   \n","1     2018-01-01 12:44:40+00:00          14595               25073877.0   \n","2     2018-01-01 12:12:00+00:00          49566                      NaN   \n","3     2017-12-31 23:43:04+00:00          35164                      NaN   \n","4     2017-12-31 22:18:20+00:00          39428                      NaN   \n","...                         ...            ...                      ...   \n","11894 2014-01-02 06:02:48+00:00             24                      NaN   \n","11895 2014-01-02 06:00:04+00:00             56                      NaN   \n","11896 2014-01-02 05:47:30+00:00             20                      NaN   \n","11897 2014-01-02 00:39:56+00:00           6764                      NaN   \n","11898 2014-01-01 12:56:30+00:00            872                      NaN   \n","\n","       favorite_count  is_retweet  \n","0               51473       False  \n","1               53557       False  \n","2              138808       False  \n","3              154769       False  \n","4              157655       False  \n","...               ...         ...  \n","11894              60       False  \n","11895              70       False  \n","11896              38       False  \n","11897            4376       False  \n","11898             644       False  \n","\n","[11899 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-7c6eb303-143e-4f45-a9e0-e7ebcffdb457\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>id_str</th>\n","      <th>text</th>\n","      <th>created_at</th>\n","      <th>retweet_count</th>\n","      <th>in_reply_to_user_id_str</th>\n","      <th>favorite_count</th>\n","      <th>is_retweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Twitter for iPhone</td>\n","      <td>947824196909961216</td>\n","      <td>Will be leaving Florida for Washington (D.C.) ...</td>\n","      <td>2018-01-01 13:37:52+00:00</td>\n","      <td>8237</td>\n","      <td>NaN</td>\n","      <td>51473</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Twitter for iPhone</td>\n","      <td>947810806430826496</td>\n","      <td>Iran is failing at every level despite the ter...</td>\n","      <td>2018-01-01 12:44:40+00:00</td>\n","      <td>14595</td>\n","      <td>25073877.0</td>\n","      <td>53557</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Twitter for iPhone</td>\n","      <td>947802588174577664</td>\n","      <td>The United States has foolishly given Pakistan...</td>\n","      <td>2018-01-01 12:12:00+00:00</td>\n","      <td>49566</td>\n","      <td>NaN</td>\n","      <td>138808</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Twitter for iPhone</td>\n","      <td>947614110082043904</td>\n","      <td>HAPPY NEW YEAR! We are MAKING AMERICA GREAT AG...</td>\n","      <td>2017-12-31 23:43:04+00:00</td>\n","      <td>35164</td>\n","      <td>NaN</td>\n","      <td>154769</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Twitter for iPhone</td>\n","      <td>947592785519173632</td>\n","      <td>As our Country rapidly grows stronger and smar...</td>\n","      <td>2017-12-31 22:18:20+00:00</td>\n","      <td>39428</td>\n","      <td>NaN</td>\n","      <td>157655</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11894</th>\n","      <td>Twitter for Android</td>\n","      <td>418623389600083968</td>\n","      <td>\"@noahshappy: @realDonaldTrump very true comme...</td>\n","      <td>2014-01-02 06:02:48+00:00</td>\n","      <td>24</td>\n","      <td>NaN</td>\n","      <td>60</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>11895</th>\n","      <td>Twitter for Android</td>\n","      <td>418622703730704384</td>\n","      <td>\"@MeleMallory: @realDonaldTrump You know it's ...</td>\n","      <td>2014-01-02 06:00:04+00:00</td>\n","      <td>56</td>\n","      <td>NaN</td>\n","      <td>70</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>11896</th>\n","      <td>Twitter for Android</td>\n","      <td>418619537740017664</td>\n","      <td>\"@ScreenPlayWritr: @realDonaldTrump Is Al Gore...</td>\n","      <td>2014-01-02 05:47:30+00:00</td>\n","      <td>20</td>\n","      <td>NaN</td>\n","      <td>38</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>11897</th>\n","      <td>Twitter for Android</td>\n","      <td>418542137899491328</td>\n","      <td>This very expensive GLOBAL WARMING bullshit ha...</td>\n","      <td>2014-01-02 00:39:56+00:00</td>\n","      <td>6764</td>\n","      <td>NaN</td>\n","      <td>4376</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>11898</th>\n","      <td>Twitter for Android</td>\n","      <td>418365112844824576</td>\n","      <td>Today is the first day of the rest of your lif...</td>\n","      <td>2014-01-01 12:56:30+00:00</td>\n","      <td>872</td>\n","      <td>NaN</td>\n","      <td>644</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11899 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c6eb303-143e-4f45-a9e0-e7ebcffdb457')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7c6eb303-143e-4f45-a9e0-e7ebcffdb457 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7c6eb303-143e-4f45-a9e0-e7ebcffdb457');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bf1de807-4fff-46ab-bb1d-6b66176f13fe\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf1de807-4fff-46ab-bb1d-6b66176f13fe')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bf1de807-4fff-46ab-bb1d-6b66176f13fe button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 11899,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Twitter for Android\",\n          \"Twitter for iPhone\",\n          \"Twitter for Websites\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244532854021539392,\n        \"min\": 418365112844824576,\n        \"max\": 1079888205351145472,\n        \"num_unique_values\": 11899,\n        \"samples\": [\n          479090300728537088,\n          1037107565413511168,\n          1050005011562926080\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11855,\n        \"samples\": [\n          \"\\\"@A_Frog_4_Life: If you're interested in 'balancing' work and pleasure, stop! Instead make your work more pleasurable - Donald Trump\",\n          \"Deals are my art form. Other people paint beautifully or write poetry. I like making deals, preferably big deals. That's how I get my kicks.\",\n          \"I agree getting Tax Cuts approved  is important (we will also get HealthCare), but perhaps no Administration has done more in its first.....\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2014-01-01 12:56:30+00:00\",\n        \"max\": \"2018-12-31 23:53:06+00:00\",\n        \"num_unique_values\": 11872,\n        \"samples\": [\n          \"2017-07-11 12:57:47+00:00\",\n          \"2014-09-12 11:13:54+00:00\",\n          \"2018-09-20 11:13:44+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweet_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12933,\n        \"min\": 0,\n        \"max\": 369530,\n        \"num_unique_values\": 6253,\n        \"samples\": [\n          12932,\n          24533,\n          20487\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"in_reply_to_user_id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 344262537.4058477,\n        \"min\": 759251.0,\n        \"max\": 2231790690.0,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          25073877.0,\n          432895323.0,\n          566952520.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"favorite_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50104,\n        \"min\": 0,\n        \"max\": 616217,\n        \"num_unique_values\": 5940,\n        \"samples\": [\n          154,\n          91711,\n          56790\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_retweet\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":19}],"source":["df.reset_index(drop=True, inplace=True)\n","df"]},{"cell_type":"markdown","metadata":{"id":"_OwrXW9diHDT"},"source":["Trump used to live on Twitter lol.\n","\n","Here, we borrow the idea of the information retrieval algorithm. We define the cosine similarity of the tweet's vector representation to the target post's vector representation as relevance, the normalized score (popularity) as importance, and normalized days apart from the debate day as recency. Then, we pick top 5 tweets for the Trump agent to learn.  "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15890,"status":"ok","timestamp":1708710538772,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"},"user_tz":0},"id":"P3Nha6jPiDlM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"de918417-7af8-4e34-c458-2e368d391aa9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentence_transformers\n","  Downloading sentence_transformers-2.4.0-py3-none-any.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.37.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n","Installing collected packages: sentence_transformers\n","Successfully installed sentence_transformers-2.4.0\n"]}],"source":["!pip install sentence_transformers\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"markdown","source":["Find the most relevant (via transformer embedding distance) piece of prior history (in your memory) that addresses the question at hand:"],"metadata":{"id":"tad-Zc_iqyq3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cSDvxjQil5_a","colab":{"base_uri":"https://localhost:8080/","height":525,"referenced_widgets":["6789b9495b854907a57cb7eb87927973","1d38da9fbd2e4b1db9cc5603fe3a73a3","857f7b5e7cce4baf915806ce2b384d83","b20c503e0991429285d8c17d7b493c4b","b288cf876256492ca6c35824e1b2d3d5","fd91e055c24f4847a381f5aade578702","32c5268660084042ae83ed310cf0ad2e","0fd7ed2927fc4890bb75cec17b711f86","0a5c780f67d6434887cd34bb925ade86","03494fff43374996954b227fdb687b3f","2acd47dcb9004f0e922c514ed8183807","409ac364e0324a769073e54e5d1da8bf","f92eb7ad55034adea7a85102dac93f49","5591ca43cb264d7dbe22c092817d0982","88ecefab67254490bb84fd3c0f135dba","9528395df8fe4da084a3e411f6e12b9c","ca1c75ad3fa240cfad20a56fba2fc99c","6440fe73609d4ec198d2b14313a54983","d1c75d4e65994b7dabc6b0fb3a3b4ac4","df6158dfaf244706916011b043d5395d","236d0080d81c47ed8c7fa138fd1792ab","d3d29fe74e414faaae96d2ae7bb596a8","e5dfc8221f1c4f0986e88a49bcc9e80a","2f9a7159bf5745a8b66d2ab2d573ce41","52b5c4c9f2b34c16987f0490552aeebd","6d60083f57184a86a6f3ede105a96e9f","effac782b9ce4d5db478af8822ab41b7","70daf950e25f4bb9a189c6b216317de9","2f6f06c188184982be1dd28059018f8b","04498d27b18c4d6d99d64b5bc30640b1","9faec3103be049c0803478c04983c3c1","cbe8a03f63a1401bb118ed733400512d","575e170aba434822aeddc35834a9c137","ecc7567a7a12499ba8dc378f0cf33336","2cabda67ac2c4eddacf02ad3afe16f03","7af29cdb84a54c07a1249577dc39d6e2","136da6f3dd274cf68f3aa72508ae2254","49ba8eebea0348fc95bc726bbf72ac90","2f1fdfdf467c483192af22640593e380","98ac27a5dc5844d38e38a91979ebdf79","9123a0b1b5794acf8666fe2df220e390","adae7841fe404cdca2a3b98b5e35dc6f","4cb4313b05574e898fecec80eeb6c74e","71fd6ed0bfaa45818a9941061d43bdfd","fe243c9237d44d4689ae429de0aa124b","815f80a7001d4aa996adbf16adbaba43","af761c5c168d4ce7a3435c7867d9c51d","4d6a73353aee4aa3b8ef1bf03ffa9b12","fb600237cccd4f7194ac65bfcf037fae","7a9c3403f73b4c7182657bf1b65b994f","d7b6810df0e44afa8f6496129ecc30ab","dfbfd0796c29475c92bccbf2f8082f5c","0a63332cfb6242f5b66667046cfe7771","c0fc505d1b674c818ac81c750eef31e9","a0bf1d94a4194733b4655f8cef1593e3","bd9b058cf6d4454e9d1b151258a10092","8bf29bafc94e48569024a33d734ae911","5bf92412209345989e3d74b061655db9","ffeca8e61aec4ac0ab3599717dd326ab","a4dca51f04234f53979d6e3c3fc906d6","d8851f8f6f88467aabd6f25dc4ea6385","6e9153b487ac4514aea5369a00aad7bf","4765b96088a04f549430653f1996c5ff","2a96bfcd0ff94f3e9bec82f434040277","01250ab780c3468cae030571b89933c0","36e0b821fcd946d9b8eb589cb10bbaa9","4a1ba1dcede8426597fef81bd428d7ef","0279241d8728444eab9cabcd8fc39f12","e328628498bf435aa173df3486f5287e","0f527cf382624bf6b7c5fbd2ba773f1d","d83209d07507487d941f909b3c063786","f7cdfb5d965d4d1fa845b0d6d7f34267","8ce7bb8afff74c7291f908fbabc4964d","8dad9721c3fb410a803bb8edfe868f0b","194ceaf6c8dd4a96bcd1324edb59e4ce","2e07c4f725834afa82a743a71566ec40","01e781df3070433baad362d7bb08b2e1","08a1b4effd0b4aa7a9ec8175a97dc13e","6775e9ef4fa3479f8ec5bd038b88f75c","35e38d0fb8944aa298b006f32bda4b9d","64c44113eba8423a95c3a1bf8cf64167","13575f00bd9d48b9a7322b61f56c702d","ca4fbfb851884131b1847c65c8778c89","f29b36b5a1ab4fc387d4f4478ecd393b","e18dc7cc356f49af96e57f93550acee9","6050b32c7d9b4431ab8caccde40871bc","c77372d15cd54e6695eac372324056e2","01a7be094ebb499b8d43e1bdd47f1acb","98cfb6bc08fa4804b4e4e463fb77b38a","d4ec3a1b57da48d190ba613594947b45","9522edae5f79451dbcc421a07d5b81b3","8744fb699c79462788e35fdb261a1b46","5d8d93dd494447a496c41f49ca3d574a","1c4671f1a1c949c0b1a37c17ec2ed398","a333f6f3447a400db47388e9e10ebd1e","f8a35171bfa34da5b0ea95b47ddce1df","ae76274bfb404d5f8bf9252af89b2323","f68ebe10449e4c3886373f05fe744081","d58fe0dcb67547a2a582ae4fc12c0ab9","bcf7d1545b7440bca0c77b2e3379afb1","be86bde53c9e4f3a9d677f8702196bc2","0ccc737c9ccb469b963b47d423b1c1a3","45861f8609644ef4bfb0913933729b21","6717201a04084dea97539e9961209384","fca86c801b87418da6d750d50c83b1fd","f4228ef3961540e5bdbb5ba0a9fa9497","dcc99fe5dbf44770b5bc1be05e414638","33f5a64520eb429f856b11918d78b901","6c729ea16a654ccfaac820c47107c071","a9f4417f49654c958b39bc7d95052e4c","d2baf3ed32fe4f58ac2e60bdfd59a802","a71eba2843954958b69bec2f4378572c","7af33cf79e364c6cb7d6a240919e7125","4fe5a07bd98b429fad97e446838eff39","46e346b7b5eb48158fd6d104dabc3b3e","f0d072bfe9d548409aa415ee7679fe8a","46c63eb291ab4ba8a2e3b9196b346720","183a97da33464664b1c619f629f5c816","75cc30e52092405fbd78b63ec501a88c","d308ce7c059549268ee5b90ae7d9b02d","e2e702d303944f9dace4b5887ac0d229"]},"executionInfo":{"status":"ok","timestamp":1708710560001,"user_tz":0,"elapsed":21230,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"}},"outputId":"116dbcf3-2a7f-454b-a31e-4c6eed3ade92"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6789b9495b854907a57cb7eb87927973"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"409ac364e0324a769073e54e5d1da8bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5dfc8221f1c4f0986e88a49bcc9e80a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecc7567a7a12499ba8dc378f0cf33336"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe243c9237d44d4689ae429de0aa124b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd9b058cf6d4454e9d1b151258a10092"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a1ba1dcede8426597fef81bd428d7ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08a1b4effd0b4aa7a9ec8175a97dc13e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98cfb6bc08fa4804b4e4e463fb77b38a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcf7d1545b7440bca0c77b2e3379afb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2baf3ed32fe4f58ac2e60bdfd59a802"}},"metadata":{}}],"source":["# relevance\n","embedding_model_name = 'all-MiniLM-L6-v2'\n","model = SentenceTransformer(embedding_model_name, device='cuda')\n","embeddings = model.encode(df['text'].astype(str))\n","target_question = 'Why is your position correct on selecting a Supreme Court nominee in an election year?'\n","similarity = cosine_similarity(embeddings, model.encode([target_question]))\n","df['cosine_similarity'] = similarity\n","df['relevance'] = (df['cosine_similarity'] - df['cosine_similarity'].min()) / (df['cosine_similarity'].max() - df['cosine_similarity'].min())"]},{"cell_type":"markdown","source":["Find the most recent memories relevant to that question:"],"metadata":{"id":"KvAOTAO4rG4U"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQdddSTwmWFo"},"outputs":[],"source":["# recency\n","dates = df['created_at'].dt.date\n","target_date = '2020-09-29'\n","df['days_diff'] = (pd.to_datetime(target_date) - pd.to_datetime(dates)).dt.days\n","df['days_diff'] = 0.99 ** df['days_diff'] # decay factor\n","df['recency'] = (df['days_diff'] - df['days_diff'].min()) / (df['days_diff'].max() - df['days_diff'].min())"]},{"cell_type":"markdown","source":["Find the most important memory, in this case, represented in terms of the number of likes, shares, and retweets:"],"metadata":{"id":"Ijz_l9-PrPnv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YRjCNsImiNi"},"outputs":[],"source":["# importance\n","scores = df['favorite_count']\n","df['importance'] = (scores - scores.min()) / (scores.max() - scores.min())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":847},"id":"LgYcmPkdzIBt","executionInfo":{"status":"ok","timestamp":1708710561095,"user_tz":0,"elapsed":325,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"}},"outputId":"5a17db53-84bd-44c9-9753-f562a9ea8cd4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    source              id_str  \\\n","0       Twitter for iPhone  947824196909961216   \n","1       Twitter for iPhone  947810806430826496   \n","2       Twitter for iPhone  947802588174577664   \n","3       Twitter for iPhone  947614110082043904   \n","4       Twitter for iPhone  947592785519173632   \n","...                    ...                 ...   \n","11894  Twitter for Android  418623389600083968   \n","11895  Twitter for Android  418622703730704384   \n","11896  Twitter for Android  418619537740017664   \n","11897  Twitter for Android  418542137899491328   \n","11898  Twitter for Android  418365112844824576   \n","\n","                                                    text  \\\n","0      Will be leaving Florida for Washington (D.C.) ...   \n","1      Iran is failing at every level despite the ter...   \n","2      The United States has foolishly given Pakistan...   \n","3      HAPPY NEW YEAR! We are MAKING AMERICA GREAT AG...   \n","4      As our Country rapidly grows stronger and smar...   \n","...                                                  ...   \n","11894  \"@noahshappy: @realDonaldTrump very true comme...   \n","11895  \"@MeleMallory: @realDonaldTrump You know it's ...   \n","11896  \"@ScreenPlayWritr: @realDonaldTrump Is Al Gore...   \n","11897  This very expensive GLOBAL WARMING bullshit ha...   \n","11898  Today is the first day of the rest of your lif...   \n","\n","                     created_at  retweet_count  in_reply_to_user_id_str  \\\n","0     2018-01-01 13:37:52+00:00           8237                      NaN   \n","1     2018-01-01 12:44:40+00:00          14595               25073877.0   \n","2     2018-01-01 12:12:00+00:00          49566                      NaN   \n","3     2017-12-31 23:43:04+00:00          35164                      NaN   \n","4     2017-12-31 22:18:20+00:00          39428                      NaN   \n","...                         ...            ...                      ...   \n","11894 2014-01-02 06:02:48+00:00             24                      NaN   \n","11895 2014-01-02 06:00:04+00:00             56                      NaN   \n","11896 2014-01-02 05:47:30+00:00             20                      NaN   \n","11897 2014-01-02 00:39:56+00:00           6764                      NaN   \n","11898 2014-01-01 12:56:30+00:00            872                      NaN   \n","\n","       favorite_count  is_retweet  cosine_similarity  relevance     days_diff  \\\n","0               51473       False           0.118164   0.367391  4.231214e-05   \n","1               53557       False          -0.038524   0.152157  4.231214e-05   \n","2              138808       False           0.003459   0.209827  4.231214e-05   \n","3              154769       False           0.096200   0.337219  4.188902e-05   \n","4              157655       False           0.100477   0.343095  4.188902e-05   \n","...               ...         ...                ...        ...           ...   \n","11894              60       False           0.023121   0.236835  1.794110e-11   \n","11895              70       False           0.048183   0.271262  1.794110e-11   \n","11896              38       False           0.181863   0.454891  1.794110e-11   \n","11897            4376       False          -0.006410   0.196271  1.794110e-11   \n","11898             644       False          -0.010654   0.190441  1.776169e-11   \n","\n","            recency  importance  \n","0      2.577571e-02    0.083531  \n","1      2.577571e-02    0.086913  \n","2      2.577571e-02    0.225258  \n","3      2.551795e-02    0.251160  \n","4      2.551795e-02    0.255843  \n","...             ...         ...  \n","11894  1.092937e-10    0.000097  \n","11895  1.092937e-10    0.000114  \n","11896  1.092937e-10    0.000062  \n","11897  1.092937e-10    0.007101  \n","11898  0.000000e+00    0.001045  \n","\n","[11899 rows x 13 columns]"],"text/html":["\n","  <div id=\"df-f96ec48f-cd85-4c50-aa4b-c07b609d8ab4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>id_str</th>\n","      <th>text</th>\n","      <th>created_at</th>\n","      <th>retweet_count</th>\n","      <th>in_reply_to_user_id_str</th>\n","      <th>favorite_count</th>\n","      <th>is_retweet</th>\n","      <th>cosine_similarity</th>\n","      <th>relevance</th>\n","      <th>days_diff</th>\n","      <th>recency</th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Twitter for iPhone</td>\n","      <td>947824196909961216</td>\n","      <td>Will be leaving Florida for Washington (D.C.) ...</td>\n","      <td>2018-01-01 13:37:52+00:00</td>\n","      <td>8237</td>\n","      <td>NaN</td>\n","      <td>51473</td>\n","      <td>False</td>\n","      <td>0.118164</td>\n","      <td>0.367391</td>\n","      <td>4.231214e-05</td>\n","      <td>2.577571e-02</td>\n","      <td>0.083531</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Twitter for iPhone</td>\n","      <td>947810806430826496</td>\n","      <td>Iran is failing at every level despite the ter...</td>\n","      <td>2018-01-01 12:44:40+00:00</td>\n","      <td>14595</td>\n","      <td>25073877.0</td>\n","      <td>53557</td>\n","      <td>False</td>\n","      <td>-0.038524</td>\n","      <td>0.152157</td>\n","      <td>4.231214e-05</td>\n","      <td>2.577571e-02</td>\n","      <td>0.086913</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Twitter for iPhone</td>\n","      <td>947802588174577664</td>\n","      <td>The United States has foolishly given Pakistan...</td>\n","      <td>2018-01-01 12:12:00+00:00</td>\n","      <td>49566</td>\n","      <td>NaN</td>\n","      <td>138808</td>\n","      <td>False</td>\n","      <td>0.003459</td>\n","      <td>0.209827</td>\n","      <td>4.231214e-05</td>\n","      <td>2.577571e-02</td>\n","      <td>0.225258</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Twitter for iPhone</td>\n","      <td>947614110082043904</td>\n","      <td>HAPPY NEW YEAR! We are MAKING AMERICA GREAT AG...</td>\n","      <td>2017-12-31 23:43:04+00:00</td>\n","      <td>35164</td>\n","      <td>NaN</td>\n","      <td>154769</td>\n","      <td>False</td>\n","      <td>0.096200</td>\n","      <td>0.337219</td>\n","      <td>4.188902e-05</td>\n","      <td>2.551795e-02</td>\n","      <td>0.251160</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Twitter for iPhone</td>\n","      <td>947592785519173632</td>\n","      <td>As our Country rapidly grows stronger and smar...</td>\n","      <td>2017-12-31 22:18:20+00:00</td>\n","      <td>39428</td>\n","      <td>NaN</td>\n","      <td>157655</td>\n","      <td>False</td>\n","      <td>0.100477</td>\n","      <td>0.343095</td>\n","      <td>4.188902e-05</td>\n","      <td>2.551795e-02</td>\n","      <td>0.255843</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11894</th>\n","      <td>Twitter for Android</td>\n","      <td>418623389600083968</td>\n","      <td>\"@noahshappy: @realDonaldTrump very true comme...</td>\n","      <td>2014-01-02 06:02:48+00:00</td>\n","      <td>24</td>\n","      <td>NaN</td>\n","      <td>60</td>\n","      <td>False</td>\n","      <td>0.023121</td>\n","      <td>0.236835</td>\n","      <td>1.794110e-11</td>\n","      <td>1.092937e-10</td>\n","      <td>0.000097</td>\n","    </tr>\n","    <tr>\n","      <th>11895</th>\n","      <td>Twitter for Android</td>\n","      <td>418622703730704384</td>\n","      <td>\"@MeleMallory: @realDonaldTrump You know it's ...</td>\n","      <td>2014-01-02 06:00:04+00:00</td>\n","      <td>56</td>\n","      <td>NaN</td>\n","      <td>70</td>\n","      <td>False</td>\n","      <td>0.048183</td>\n","      <td>0.271262</td>\n","      <td>1.794110e-11</td>\n","      <td>1.092937e-10</td>\n","      <td>0.000114</td>\n","    </tr>\n","    <tr>\n","      <th>11896</th>\n","      <td>Twitter for Android</td>\n","      <td>418619537740017664</td>\n","      <td>\"@ScreenPlayWritr: @realDonaldTrump Is Al Gore...</td>\n","      <td>2014-01-02 05:47:30+00:00</td>\n","      <td>20</td>\n","      <td>NaN</td>\n","      <td>38</td>\n","      <td>False</td>\n","      <td>0.181863</td>\n","      <td>0.454891</td>\n","      <td>1.794110e-11</td>\n","      <td>1.092937e-10</td>\n","      <td>0.000062</td>\n","    </tr>\n","    <tr>\n","      <th>11897</th>\n","      <td>Twitter for Android</td>\n","      <td>418542137899491328</td>\n","      <td>This very expensive GLOBAL WARMING bullshit ha...</td>\n","      <td>2014-01-02 00:39:56+00:00</td>\n","      <td>6764</td>\n","      <td>NaN</td>\n","      <td>4376</td>\n","      <td>False</td>\n","      <td>-0.006410</td>\n","      <td>0.196271</td>\n","      <td>1.794110e-11</td>\n","      <td>1.092937e-10</td>\n","      <td>0.007101</td>\n","    </tr>\n","    <tr>\n","      <th>11898</th>\n","      <td>Twitter for Android</td>\n","      <td>418365112844824576</td>\n","      <td>Today is the first day of the rest of your lif...</td>\n","      <td>2014-01-01 12:56:30+00:00</td>\n","      <td>872</td>\n","      <td>NaN</td>\n","      <td>644</td>\n","      <td>False</td>\n","      <td>-0.010654</td>\n","      <td>0.190441</td>\n","      <td>1.776169e-11</td>\n","      <td>0.000000e+00</td>\n","      <td>0.001045</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11899 rows × 13 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f96ec48f-cd85-4c50-aa4b-c07b609d8ab4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f96ec48f-cd85-4c50-aa4b-c07b609d8ab4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f96ec48f-cd85-4c50-aa4b-c07b609d8ab4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-22a08adf-ab50-4dcb-a861-c5e651e025de\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22a08adf-ab50-4dcb-a861-c5e651e025de')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-22a08adf-ab50-4dcb-a861-c5e651e025de button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 11899,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Twitter for Android\",\n          \"Twitter for iPhone\",\n          \"Twitter for Websites\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244532854021539392,\n        \"min\": 418365112844824576,\n        \"max\": 1079888205351145472,\n        \"num_unique_values\": 11899,\n        \"samples\": [\n          479090300728537088,\n          1037107565413511168,\n          1050005011562926080\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11855,\n        \"samples\": [\n          \"\\\"@A_Frog_4_Life: If you're interested in 'balancing' work and pleasure, stop! Instead make your work more pleasurable - Donald Trump\",\n          \"Deals are my art form. Other people paint beautifully or write poetry. I like making deals, preferably big deals. That's how I get my kicks.\",\n          \"I agree getting Tax Cuts approved  is important (we will also get HealthCare), but perhaps no Administration has done more in its first.....\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2014-01-01 12:56:30+00:00\",\n        \"max\": \"2018-12-31 23:53:06+00:00\",\n        \"num_unique_values\": 11872,\n        \"samples\": [\n          \"2017-07-11 12:57:47+00:00\",\n          \"2014-09-12 11:13:54+00:00\",\n          \"2018-09-20 11:13:44+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweet_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12933,\n        \"min\": 0,\n        \"max\": 369530,\n        \"num_unique_values\": 6253,\n        \"samples\": [\n          12932,\n          24533,\n          20487\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"in_reply_to_user_id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 344262537.4058477,\n        \"min\": 759251.0,\n        \"max\": 2231790690.0,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          25073877.0,\n          432895323.0,\n          566952520.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"favorite_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50104,\n        \"min\": 0,\n        \"max\": 616217,\n        \"num_unique_values\": 5940,\n        \"samples\": [\n          154,\n          91711,\n          56790\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_retweet\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cosine_similarity\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 11849,\n        \"samples\": [\n          0.062280893325805664,\n          0.12882499396800995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 11846,\n        \"samples\": [\n          0.41621166467666626,\n          0.3820353150367737\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"days_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0003140963946255719,\n        \"min\": 1.776169032077608e-11,\n        \"max\": 0.0016415501428270432,\n        \"num_unique_values\": 1068,\n        \"samples\": [\n          4.969376171501411e-05,\n          4.8268857545700025e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1913413363561269,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1068,\n        \"samples\": [\n          0.030272449920678113,\n          0.0029404328988659524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08131021823774882,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5940,\n        \"samples\": [\n          0.00024991196283127533,\n          0.14882906508583826\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":24}],"source":["df"]},{"cell_type":"markdown","source":["Now, we create a function that combines relevance, recency, and importance (here with equal and additive contribution):"],"metadata":{"id":"N0C4VZu2rd0B"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GuzvOKSvm-sS","colab":{"base_uri":"https://localhost:8080/","height":581},"executionInfo":{"status":"ok","timestamp":1708710561095,"user_tz":0,"elapsed":13,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"}},"outputId":"3c702503-3632-42d9-c979-4b896de933fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  source               id_str  \\\n","2648  Twitter for iPhone  1077549301449060352   \n","3630  Twitter for iPhone  1045444544068812800   \n","2836  Twitter for iPhone  1071076519584268288   \n","2607  Twitter for iPhone  1079830267274108928   \n","2678  Twitter for iPhone  1076655729820471296   \n","\n","                                                   text  \\\n","2648                                   Merry Christmas!   \n","3630  Judge Kavanaugh showed America exactly why I n...   \n","2836  I am pleased to announce that I will be nomina...   \n","2607  Heads of countries are calling wanting to know...   \n","2678  Brett McGurk, who I do not know, was appointed...   \n","\n","                    created_at  retweet_count  in_reply_to_user_id_str  \\\n","2648 2018-12-25 12:59:08+00:00          89255                      NaN   \n","3630 2018-09-27 22:46:17+00:00          84180                      NaN   \n","2836 2018-12-07 16:18:36+00:00          13779                      NaN   \n","2607 2018-12-31 20:02:52+00:00          21030                      NaN   \n","2678 2018-12-23 01:48:23+00:00          19476                      NaN   \n","\n","      favorite_count  is_retweet  cosine_similarity  relevance  days_diff  \\\n","2648          508372       False          -0.025833   0.169590   0.001545   \n","3630          320104       False           0.509458   0.904891   0.000632   \n","2836           65313       False           0.464247   0.842787   0.001290   \n","2607           76721       False           0.292551   0.606938   0.001642   \n","2678           86619       False           0.334501   0.664562   0.001515   \n","\n","       recency  importance     score  \n","2648  0.941480    0.824989  1.936058  \n","3630  0.384896    0.519466  1.809253  \n","2836  0.785678    0.105990  1.734456  \n","2607  1.000000    0.124503  1.731441  \n","2678  0.922745    0.140566  1.727872  "],"text/html":["\n","  <div id=\"df-a8a24485-3b98-48a7-a15f-db0351c407ba\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>id_str</th>\n","      <th>text</th>\n","      <th>created_at</th>\n","      <th>retweet_count</th>\n","      <th>in_reply_to_user_id_str</th>\n","      <th>favorite_count</th>\n","      <th>is_retweet</th>\n","      <th>cosine_similarity</th>\n","      <th>relevance</th>\n","      <th>days_diff</th>\n","      <th>recency</th>\n","      <th>importance</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2648</th>\n","      <td>Twitter for iPhone</td>\n","      <td>1077549301449060352</td>\n","      <td>Merry Christmas!</td>\n","      <td>2018-12-25 12:59:08+00:00</td>\n","      <td>89255</td>\n","      <td>NaN</td>\n","      <td>508372</td>\n","      <td>False</td>\n","      <td>-0.025833</td>\n","      <td>0.169590</td>\n","      <td>0.001545</td>\n","      <td>0.941480</td>\n","      <td>0.824989</td>\n","      <td>1.936058</td>\n","    </tr>\n","    <tr>\n","      <th>3630</th>\n","      <td>Twitter for iPhone</td>\n","      <td>1045444544068812800</td>\n","      <td>Judge Kavanaugh showed America exactly why I n...</td>\n","      <td>2018-09-27 22:46:17+00:00</td>\n","      <td>84180</td>\n","      <td>NaN</td>\n","      <td>320104</td>\n","      <td>False</td>\n","      <td>0.509458</td>\n","      <td>0.904891</td>\n","      <td>0.000632</td>\n","      <td>0.384896</td>\n","      <td>0.519466</td>\n","      <td>1.809253</td>\n","    </tr>\n","    <tr>\n","      <th>2836</th>\n","      <td>Twitter for iPhone</td>\n","      <td>1071076519584268288</td>\n","      <td>I am pleased to announce that I will be nomina...</td>\n","      <td>2018-12-07 16:18:36+00:00</td>\n","      <td>13779</td>\n","      <td>NaN</td>\n","      <td>65313</td>\n","      <td>False</td>\n","      <td>0.464247</td>\n","      <td>0.842787</td>\n","      <td>0.001290</td>\n","      <td>0.785678</td>\n","      <td>0.105990</td>\n","      <td>1.734456</td>\n","    </tr>\n","    <tr>\n","      <th>2607</th>\n","      <td>Twitter for iPhone</td>\n","      <td>1079830267274108928</td>\n","      <td>Heads of countries are calling wanting to know...</td>\n","      <td>2018-12-31 20:02:52+00:00</td>\n","      <td>21030</td>\n","      <td>NaN</td>\n","      <td>76721</td>\n","      <td>False</td>\n","      <td>0.292551</td>\n","      <td>0.606938</td>\n","      <td>0.001642</td>\n","      <td>1.000000</td>\n","      <td>0.124503</td>\n","      <td>1.731441</td>\n","    </tr>\n","    <tr>\n","      <th>2678</th>\n","      <td>Twitter for iPhone</td>\n","      <td>1076655729820471296</td>\n","      <td>Brett McGurk, who I do not know, was appointed...</td>\n","      <td>2018-12-23 01:48:23+00:00</td>\n","      <td>19476</td>\n","      <td>NaN</td>\n","      <td>86619</td>\n","      <td>False</td>\n","      <td>0.334501</td>\n","      <td>0.664562</td>\n","      <td>0.001515</td>\n","      <td>0.922745</td>\n","      <td>0.140566</td>\n","      <td>1.727872</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8a24485-3b98-48a7-a15f-db0351c407ba')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a8a24485-3b98-48a7-a15f-db0351c407ba button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a8a24485-3b98-48a7-a15f-db0351c407ba');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ebc40001-8442-4cee-888f-64280023d4b0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebc40001-8442-4cee-888f-64280023d4b0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ebc40001-8442-4cee-888f-64280023d4b0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 11899,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Twitter for iPad\",\n          \"Twitter for iPhone\",\n          \"Twitlonger\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244532854021539392,\n        \"min\": 418365112844824576,\n        \"max\": 1079888205351145472,\n        \"num_unique_values\": 11899,\n        \"samples\": [\n          923546192511946752,\n          977159683151712256,\n          543700405604339712\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11855,\n        \"samples\": [\n          \"\\\"@jeddprice: @realDonaldTrump Maybe the USA needs to cancel all the rest of Obama's vacations to actually deal with this.\\\"\",\n          \"\\\"@Drake4444444                    \\nthe only way to fix health care crisis is for you to run for Pres &amp; bring common sense back to govt\\\" Thx.\",\n          \"......MAKE FRANCE GREAT AGAIN!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2014-01-01 12:56:30+00:00\",\n        \"max\": \"2018-12-31 23:53:06+00:00\",\n        \"num_unique_values\": 11872,\n        \"samples\": [\n          \"2018-04-25 11:53:36+00:00\",\n          \"2014-06-01 00:55:12+00:00\",\n          \"2014-10-15 16:18:27+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweet_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12933,\n        \"min\": 0,\n        \"max\": 369530,\n        \"num_unique_values\": 6253,\n        \"samples\": [\n          29452,\n          11846,\n          9254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"in_reply_to_user_id_str\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 344262537.4058477,\n        \"min\": 759251.0,\n        \"max\": 2231790690.0,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          25073877.0,\n          282578001.0,\n          15084853.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"favorite_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50104,\n        \"min\": 0,\n        \"max\": 616217,\n        \"num_unique_values\": 5940,\n        \"samples\": [\n          37547,\n          70931,\n          59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_retweet\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cosine_similarity\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 11849,\n        \"samples\": [\n          0.02068699151277542,\n          0.18732097744941711\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 11846,\n        \"samples\": [\n          0.32346102595329285,\n          0.46238821744918823\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"days_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00031409639462557184,\n        \"min\": 1.776169032077608e-11,\n        \"max\": 0.0016415501428270432,\n        \"num_unique_values\": 1068,\n        \"samples\": [\n          2.995395511595202e-11,\n          0.00016766535271071751\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19134133635612688,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1068,\n        \"samples\": [\n          7.427287543041394e-09,\n          0.10213841928363422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08131021823774882,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5940,\n        \"samples\": [\n          0.06093145758718114,\n          0.1151071781531506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2606780769976757,\n        \"min\": 0.011552770506056203,\n        \"max\": 1.9360582680637455,\n        \"num_unique_values\": 11896,\n        \"samples\": [\n          0.5951778898072208,\n          0.33441345896834085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":25}],"source":["# select top 5\n","df['score'] = df['relevance'] + df['recency'] + df['importance']\n","df = df.sort_values(by='score', ascending=False)\n","df.head(5)"]},{"cell_type":"markdown","metadata":{"id":"NsFEL0eczIBt"},"source":["Let's put the top 5 tweets into the prompt (Trump) and re-run the code:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ankzgBhzIBt"},"outputs":[],"source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferMemory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jt7RzfPEzIBt"},"outputs":[],"source":["from langchain.llms import OpenAI\n","\n","llm_openai = OpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo-instruct\", max_tokens=512)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cciqx5UbzIBt","executionInfo":{"status":"ok","timestamp":1708710561096,"user_tz":0,"elapsed":13,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"}},"outputId":"73660ce9-d1a9-47f8-eb89-b8f238b952a5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Merry Christmas!',\n"," 'Judge Kavanaugh showed America exactly why I nominated him. His testimony was powerful, honest, and riveting. Democrats’ search and destroy strategy is disgraceful and this process has been a total sham and effort to delay, obstruct, and resist. The Senate must vote!',\n"," 'I am pleased to announce that I will be nominating The Honorable William P. Barr for the position of Attorney General of the United States. As the former AG for George H.W. Bush....',\n"," 'Heads of countries are calling wanting to know why Senator Schumer is not approving their otherwise approved Ambassadors!? Likewise in Government lawyers and others are being delayed at a record pace! 360 great and hardworking people are waiting for approval from....',\n"," 'Brett McGurk, who I do not know, was appointed by President Obama in 2015. Was supposed to leave in February but he just resigned prior to leaving. Grandstander? The Fake News is making such a big deal about this nothing event!']"]},"metadata":{},"execution_count":28}],"source":["df.head(5)['text'].tolist()"]},{"cell_type":"markdown","metadata":{"id":"0ZHDjsdxzIBt"},"source":["Great, we saw Judge Kavanaugh and topics like border walls appeared.\n","\n","## NOTE!\n","\n","The code below might be a little confusing in terms of the names as the Trump template has a prompt relating to Biden, and vice versa. This is because when we later construct the conversation chain, we get a \"response\" from the other end - so the Biden response comes from a Trump conversation chain.\n","\n","You can also swap these names around if it makes more sense (note it won't effect the actual functioning!)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFrIHTXpzIBt"},"outputs":[],"source":["Trump_memory = ConversationBufferMemory(human_prefix='Trump', ai_prefix='Biden')\n","Biden_memory = ConversationBufferMemory(human_prefix='Biden', ai_prefix='Trump')\n","\n","Trump_template = \"\"\"Imagine you're the Democrats presidential candidate Joe Biden. Today is Tuesday, September 29, 2020, and you're engaged in your first television presidential debate with Donald Trump. The deabte question is: Why is your position correct on selecting a Supreme Court nominee in an election year?\n","\n","Current conversation:\n","{history}\n","Trump: {input}\n","Biden:\"\"\"\n","\n","tweets = df.head(5)['text'].tolist()\n","Biden_template = \"\"\"\"Imagine you're the Republican presidential candidate Donald Trump. To give you a better sense of how Trump may give public comments, here're some of his tweets:\n","    1. Merry Christmas!\n","    2. Judge Kavanaugh showed America exactly why I nominated him. His testimony was powerful, honest, and riveting. Democrats’ search and destroy strategy is disgraceful and this process has been a total sham and effort to delay, obstruct, and resist. The Senate must vote!\n","    3. Heads of countries are calling wanting to know why Senator Schumer is not approving their otherwise approved Ambassadors!? Likewise in Government lawyers and others are being delayed at a record pace! 360 great and hardworking people are waiting for approval from....\n","    4. President and Mrs. Obama built/has a ten foot Wall around their D.C. mansion/compound. I agree, totally necessary for their safety and security. The U.S. needs the same thing, slightly larger version!\n","    5. Brett McGurk, who I do not know, was appointed by President Obama in 2015. Was supposed to leave in February but he just resigned prior to leaving. Grandstander? The Fake News is making such a big deal about this nothing event!\n","Today is Tuesday, September 29, 2020, and you're engaged in your first television presidential debate with Joe Biden. The deabte question is: Why is your position correct on selecting a Supreme Court nominee in an election year?\n","\n","Current conversation:\n","{history}\n","Biden: {input}\n","Trump:\"\"\"\n","\n","# By default, models recognize themselves as AIs. So we need to let them do role play\n","# and convince them that they're talking to real Trump/Biden (though they're not)\n","\n","TRUMP_PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=Trump_template)\n","BIDEN_PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=Biden_template)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MzDEECwUzIBt"},"outputs":[],"source":["Trump_conversation = ConversationChain(\n","    prompt=TRUMP_PROMPT,\n","    llm=llm_openai,\n","    verbose=False,\n","    memory=Trump_memory\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11cJDrtNzIBt"},"outputs":[],"source":["# suppose Biden starts first\n","biden_response = Trump_conversation.predict(input='')"]},{"cell_type":"code","source":["# use the same biden response\n","biden_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"dhCvJ_DD3G9L","executionInfo":{"status":"ok","timestamp":1708710598253,"user_tz":0,"elapsed":4,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"}},"outputId":"aca5f32a-4678-4a4e-8cf3-1bdff84c0f13"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\nThank you for the question. I believe my position on selecting a Supreme Court nominee in an election year is the correct one because it follows the precedent set by past administrations.\\n\\nIn 2016, when President Obama nominated Merrick Garland to the Supreme Court, the Republican-controlled Senate refused to even hold a hearing for him, claiming that it was an election year and the next president should make the nomination. Now, just four years later, they are rushing to confirm a nominee in the final months of an election.\\n\\nThis is a clear display of hypocrisy and goes against the principle of fairness and consistency. The American people deserve to have a say in the direction of the Supreme Court through their vote in this election.\\n\\nFurthermore, rushing through a nomination so close to an election sets a dangerous precedent and undermines the integrity of the Court. We should not be making such important decisions in a rushed and partisan manner.\\n\\nI believe the Senate should follow the same standard that they set in 2016 and allow the next president to make the nomination. This will ensure that the American people have a voice in the process and that the Court remains a fair and impartial body. Thank you.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QE9HEK2UzIBt"},"outputs":[],"source":["Biden_conversation = ConversationChain(\n","    prompt=BIDEN_PROMPT,\n","    llm=llm_openai,\n","    verbose=False,\n","    memory=Biden_memory\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lJ7GEXuDzIBt"},"outputs":[],"source":["trump_response = Biden_conversation.predict(input=biden_response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"MZoIG56hzIBt","executionInfo":{"status":"ok","timestamp":1708710617667,"user_tz":0,"elapsed":3,"user":{"displayName":"Bhargav Srinivasa Desikan","userId":"08721149597132587669"}},"outputId":"9e06a592-900b-4407-ab4a-be2f5a3c33c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n\\nWell, first of all, let me just say that I am honored to be here with all of you watching tonight. And you know what? I have to agree with Joe on one thing, which is that this is an important decision. And as the President, it is my duty to nominate a Supreme Court Justice who will uphold our Constitution and protect the rights of all Americans.\\n\\nBut let's be real, folks. The Democrats are just trying to play games and delay this process. They don't want to see another conservative Justice on the Court, so they are using this election as an excuse to block my nomination.\\n\\nNow, let me remind everyone that in 2016, the American people spoke loud and clear when they elected me as their president. And they didn't elect me for just three years, they elected me for four years. So it is my responsibility and my right to nominate someone for the Supreme Court, and the Senate has a duty to vote on that nominee.\\n\\nAnd let's talk about the precedent. In the past, there have been 29 times when a vacancy occurred in an election year and the president made a nomination. In 19 of those cases, the Senate confirmed the nominee. So this is not unprecedented, and in fact, it is their constitutional duty to vote on my nominee.\\n\\nAnd let's not forget, we are in a different situation now. We are facing a global pandemic, economic crisis, and civil unrest. We need a fully-staffed Supreme Court to make important decisions and uphold our laws. We can't afford to wait until after the election to fill this vacancy.\\n\\nSo my position is clear. I have the right to make a nomination and the Senate has the responsibility to vote on it. Let's stop playing games and do what is best for the American people. Thank you.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}],"source":["trump_response"]},{"cell_type":"markdown","source":["Interestingly, the agent's response sounds more like Trump by starting with a harsh response to Biden's statement."],"metadata":{"id":"-cb2qr4I3jG2"}},{"cell_type":"markdown","metadata":{"id":"LkoPr9CQu4T2"},"source":["## <font color=\"red\">*Exercise 4*</font>\n","\n","<font color=\"red\">Use LangChain(you're welcome to not use it) to set up conversations with LLM agents for questions related to your final project (if relevant), or think of a scenario that a simulated conversation could be useful to answer a research question and find a dataset to implement it. What does it reveal about the social game involved with your dataset?\n","\n","<font color=\"red\"> Stretch: Use the idea of memory retrieval(or other methods) to design better templates for the LLM conversation."]},{"cell_type":"code","source":[],"metadata":{"id":"cRQvTtPZ442g"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"gpuType":"T4","provenance":[{"file_id":"13nBzdw6xsyMmHtH-PhGECnRfELSKKOHE","timestamp":1708720332767},{"file_id":"1No6GtUZzFE9x9-yJ1w0f-v5eGYLEh4G-","timestamp":1708704053783},{"file_id":"https://github.com/UChicago-Computational-Content-Analysis/Homework-Notebooks/blob/main/week-8/8-Conversation-and-Text-Generation.ipynb","timestamp":1708201322949}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6789b9495b854907a57cb7eb87927973":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d38da9fbd2e4b1db9cc5603fe3a73a3","IPY_MODEL_857f7b5e7cce4baf915806ce2b384d83","IPY_MODEL_b20c503e0991429285d8c17d7b493c4b"],"layout":"IPY_MODEL_b288cf876256492ca6c35824e1b2d3d5"}},"1d38da9fbd2e4b1db9cc5603fe3a73a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd91e055c24f4847a381f5aade578702","placeholder":"​","style":"IPY_MODEL_32c5268660084042ae83ed310cf0ad2e","value":"modules.json: 100%"}},"857f7b5e7cce4baf915806ce2b384d83":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fd7ed2927fc4890bb75cec17b711f86","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0a5c780f67d6434887cd34bb925ade86","value":349}},"b20c503e0991429285d8c17d7b493c4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03494fff43374996954b227fdb687b3f","placeholder":"​","style":"IPY_MODEL_2acd47dcb9004f0e922c514ed8183807","value":" 349/349 [00:00&lt;00:00, 10.9kB/s]"}},"b288cf876256492ca6c35824e1b2d3d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd91e055c24f4847a381f5aade578702":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32c5268660084042ae83ed310cf0ad2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fd7ed2927fc4890bb75cec17b711f86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a5c780f67d6434887cd34bb925ade86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03494fff43374996954b227fdb687b3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2acd47dcb9004f0e922c514ed8183807":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"409ac364e0324a769073e54e5d1da8bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f92eb7ad55034adea7a85102dac93f49","IPY_MODEL_5591ca43cb264d7dbe22c092817d0982","IPY_MODEL_88ecefab67254490bb84fd3c0f135dba"],"layout":"IPY_MODEL_9528395df8fe4da084a3e411f6e12b9c"}},"f92eb7ad55034adea7a85102dac93f49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca1c75ad3fa240cfad20a56fba2fc99c","placeholder":"​","style":"IPY_MODEL_6440fe73609d4ec198d2b14313a54983","value":"config_sentence_transformers.json: 100%"}},"5591ca43cb264d7dbe22c092817d0982":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1c75d4e65994b7dabc6b0fb3a3b4ac4","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df6158dfaf244706916011b043d5395d","value":116}},"88ecefab67254490bb84fd3c0f135dba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_236d0080d81c47ed8c7fa138fd1792ab","placeholder":"​","style":"IPY_MODEL_d3d29fe74e414faaae96d2ae7bb596a8","value":" 116/116 [00:00&lt;00:00, 4.49kB/s]"}},"9528395df8fe4da084a3e411f6e12b9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca1c75ad3fa240cfad20a56fba2fc99c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6440fe73609d4ec198d2b14313a54983":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1c75d4e65994b7dabc6b0fb3a3b4ac4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df6158dfaf244706916011b043d5395d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"236d0080d81c47ed8c7fa138fd1792ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3d29fe74e414faaae96d2ae7bb596a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5dfc8221f1c4f0986e88a49bcc9e80a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f9a7159bf5745a8b66d2ab2d573ce41","IPY_MODEL_52b5c4c9f2b34c16987f0490552aeebd","IPY_MODEL_6d60083f57184a86a6f3ede105a96e9f"],"layout":"IPY_MODEL_effac782b9ce4d5db478af8822ab41b7"}},"2f9a7159bf5745a8b66d2ab2d573ce41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70daf950e25f4bb9a189c6b216317de9","placeholder":"​","style":"IPY_MODEL_2f6f06c188184982be1dd28059018f8b","value":"README.md: 100%"}},"52b5c4c9f2b34c16987f0490552aeebd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04498d27b18c4d6d99d64b5bc30640b1","max":10659,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9faec3103be049c0803478c04983c3c1","value":10659}},"6d60083f57184a86a6f3ede105a96e9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbe8a03f63a1401bb118ed733400512d","placeholder":"​","style":"IPY_MODEL_575e170aba434822aeddc35834a9c137","value":" 10.7k/10.7k [00:00&lt;00:00, 526kB/s]"}},"effac782b9ce4d5db478af8822ab41b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70daf950e25f4bb9a189c6b216317de9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f6f06c188184982be1dd28059018f8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04498d27b18c4d6d99d64b5bc30640b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9faec3103be049c0803478c04983c3c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbe8a03f63a1401bb118ed733400512d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"575e170aba434822aeddc35834a9c137":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecc7567a7a12499ba8dc378f0cf33336":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2cabda67ac2c4eddacf02ad3afe16f03","IPY_MODEL_7af29cdb84a54c07a1249577dc39d6e2","IPY_MODEL_136da6f3dd274cf68f3aa72508ae2254"],"layout":"IPY_MODEL_49ba8eebea0348fc95bc726bbf72ac90"}},"2cabda67ac2c4eddacf02ad3afe16f03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f1fdfdf467c483192af22640593e380","placeholder":"​","style":"IPY_MODEL_98ac27a5dc5844d38e38a91979ebdf79","value":"sentence_bert_config.json: 100%"}},"7af29cdb84a54c07a1249577dc39d6e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9123a0b1b5794acf8666fe2df220e390","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adae7841fe404cdca2a3b98b5e35dc6f","value":53}},"136da6f3dd274cf68f3aa72508ae2254":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cb4313b05574e898fecec80eeb6c74e","placeholder":"​","style":"IPY_MODEL_71fd6ed0bfaa45818a9941061d43bdfd","value":" 53.0/53.0 [00:00&lt;00:00, 1.08kB/s]"}},"49ba8eebea0348fc95bc726bbf72ac90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f1fdfdf467c483192af22640593e380":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98ac27a5dc5844d38e38a91979ebdf79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9123a0b1b5794acf8666fe2df220e390":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adae7841fe404cdca2a3b98b5e35dc6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4cb4313b05574e898fecec80eeb6c74e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71fd6ed0bfaa45818a9941061d43bdfd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe243c9237d44d4689ae429de0aa124b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_815f80a7001d4aa996adbf16adbaba43","IPY_MODEL_af761c5c168d4ce7a3435c7867d9c51d","IPY_MODEL_4d6a73353aee4aa3b8ef1bf03ffa9b12"],"layout":"IPY_MODEL_fb600237cccd4f7194ac65bfcf037fae"}},"815f80a7001d4aa996adbf16adbaba43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a9c3403f73b4c7182657bf1b65b994f","placeholder":"​","style":"IPY_MODEL_d7b6810df0e44afa8f6496129ecc30ab","value":"config.json: 100%"}},"af761c5c168d4ce7a3435c7867d9c51d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfbfd0796c29475c92bccbf2f8082f5c","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0a63332cfb6242f5b66667046cfe7771","value":612}},"4d6a73353aee4aa3b8ef1bf03ffa9b12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0fc505d1b674c818ac81c750eef31e9","placeholder":"​","style":"IPY_MODEL_a0bf1d94a4194733b4655f8cef1593e3","value":" 612/612 [00:00&lt;00:00, 17.7kB/s]"}},"fb600237cccd4f7194ac65bfcf037fae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a9c3403f73b4c7182657bf1b65b994f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7b6810df0e44afa8f6496129ecc30ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfbfd0796c29475c92bccbf2f8082f5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a63332cfb6242f5b66667046cfe7771":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0fc505d1b674c818ac81c750eef31e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0bf1d94a4194733b4655f8cef1593e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd9b058cf6d4454e9d1b151258a10092":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8bf29bafc94e48569024a33d734ae911","IPY_MODEL_5bf92412209345989e3d74b061655db9","IPY_MODEL_ffeca8e61aec4ac0ab3599717dd326ab"],"layout":"IPY_MODEL_a4dca51f04234f53979d6e3c3fc906d6"}},"8bf29bafc94e48569024a33d734ae911":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8851f8f6f88467aabd6f25dc4ea6385","placeholder":"​","style":"IPY_MODEL_6e9153b487ac4514aea5369a00aad7bf","value":"pytorch_model.bin: 100%"}},"5bf92412209345989e3d74b061655db9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4765b96088a04f549430653f1996c5ff","max":90888945,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a96bfcd0ff94f3e9bec82f434040277","value":90888945}},"ffeca8e61aec4ac0ab3599717dd326ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01250ab780c3468cae030571b89933c0","placeholder":"​","style":"IPY_MODEL_36e0b821fcd946d9b8eb589cb10bbaa9","value":" 90.9M/90.9M [00:00&lt;00:00, 98.2MB/s]"}},"a4dca51f04234f53979d6e3c3fc906d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8851f8f6f88467aabd6f25dc4ea6385":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e9153b487ac4514aea5369a00aad7bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4765b96088a04f549430653f1996c5ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a96bfcd0ff94f3e9bec82f434040277":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01250ab780c3468cae030571b89933c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36e0b821fcd946d9b8eb589cb10bbaa9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a1ba1dcede8426597fef81bd428d7ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0279241d8728444eab9cabcd8fc39f12","IPY_MODEL_e328628498bf435aa173df3486f5287e","IPY_MODEL_0f527cf382624bf6b7c5fbd2ba773f1d"],"layout":"IPY_MODEL_d83209d07507487d941f909b3c063786"}},"0279241d8728444eab9cabcd8fc39f12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7cdfb5d965d4d1fa845b0d6d7f34267","placeholder":"​","style":"IPY_MODEL_8ce7bb8afff74c7291f908fbabc4964d","value":"tokenizer_config.json: 100%"}},"e328628498bf435aa173df3486f5287e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dad9721c3fb410a803bb8edfe868f0b","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_194ceaf6c8dd4a96bcd1324edb59e4ce","value":350}},"0f527cf382624bf6b7c5fbd2ba773f1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e07c4f725834afa82a743a71566ec40","placeholder":"​","style":"IPY_MODEL_01e781df3070433baad362d7bb08b2e1","value":" 350/350 [00:00&lt;00:00, 7.66kB/s]"}},"d83209d07507487d941f909b3c063786":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7cdfb5d965d4d1fa845b0d6d7f34267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ce7bb8afff74c7291f908fbabc4964d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8dad9721c3fb410a803bb8edfe868f0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"194ceaf6c8dd4a96bcd1324edb59e4ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e07c4f725834afa82a743a71566ec40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01e781df3070433baad362d7bb08b2e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08a1b4effd0b4aa7a9ec8175a97dc13e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6775e9ef4fa3479f8ec5bd038b88f75c","IPY_MODEL_35e38d0fb8944aa298b006f32bda4b9d","IPY_MODEL_64c44113eba8423a95c3a1bf8cf64167"],"layout":"IPY_MODEL_13575f00bd9d48b9a7322b61f56c702d"}},"6775e9ef4fa3479f8ec5bd038b88f75c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca4fbfb851884131b1847c65c8778c89","placeholder":"​","style":"IPY_MODEL_f29b36b5a1ab4fc387d4f4478ecd393b","value":"vocab.txt: 100%"}},"35e38d0fb8944aa298b006f32bda4b9d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e18dc7cc356f49af96e57f93550acee9","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6050b32c7d9b4431ab8caccde40871bc","value":231508}},"64c44113eba8423a95c3a1bf8cf64167":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c77372d15cd54e6695eac372324056e2","placeholder":"​","style":"IPY_MODEL_01a7be094ebb499b8d43e1bdd47f1acb","value":" 232k/232k [00:00&lt;00:00, 3.41MB/s]"}},"13575f00bd9d48b9a7322b61f56c702d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca4fbfb851884131b1847c65c8778c89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f29b36b5a1ab4fc387d4f4478ecd393b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e18dc7cc356f49af96e57f93550acee9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6050b32c7d9b4431ab8caccde40871bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c77372d15cd54e6695eac372324056e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01a7be094ebb499b8d43e1bdd47f1acb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98cfb6bc08fa4804b4e4e463fb77b38a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4ec3a1b57da48d190ba613594947b45","IPY_MODEL_9522edae5f79451dbcc421a07d5b81b3","IPY_MODEL_8744fb699c79462788e35fdb261a1b46"],"layout":"IPY_MODEL_5d8d93dd494447a496c41f49ca3d574a"}},"d4ec3a1b57da48d190ba613594947b45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c4671f1a1c949c0b1a37c17ec2ed398","placeholder":"​","style":"IPY_MODEL_a333f6f3447a400db47388e9e10ebd1e","value":"tokenizer.json: 100%"}},"9522edae5f79451dbcc421a07d5b81b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8a35171bfa34da5b0ea95b47ddce1df","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae76274bfb404d5f8bf9252af89b2323","value":466247}},"8744fb699c79462788e35fdb261a1b46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f68ebe10449e4c3886373f05fe744081","placeholder":"​","style":"IPY_MODEL_d58fe0dcb67547a2a582ae4fc12c0ab9","value":" 466k/466k [00:00&lt;00:00, 9.44MB/s]"}},"5d8d93dd494447a496c41f49ca3d574a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c4671f1a1c949c0b1a37c17ec2ed398":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a333f6f3447a400db47388e9e10ebd1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8a35171bfa34da5b0ea95b47ddce1df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae76274bfb404d5f8bf9252af89b2323":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f68ebe10449e4c3886373f05fe744081":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d58fe0dcb67547a2a582ae4fc12c0ab9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcf7d1545b7440bca0c77b2e3379afb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be86bde53c9e4f3a9d677f8702196bc2","IPY_MODEL_0ccc737c9ccb469b963b47d423b1c1a3","IPY_MODEL_45861f8609644ef4bfb0913933729b21"],"layout":"IPY_MODEL_6717201a04084dea97539e9961209384"}},"be86bde53c9e4f3a9d677f8702196bc2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fca86c801b87418da6d750d50c83b1fd","placeholder":"​","style":"IPY_MODEL_f4228ef3961540e5bdbb5ba0a9fa9497","value":"special_tokens_map.json: 100%"}},"0ccc737c9ccb469b963b47d423b1c1a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcc99fe5dbf44770b5bc1be05e414638","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33f5a64520eb429f856b11918d78b901","value":112}},"45861f8609644ef4bfb0913933729b21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c729ea16a654ccfaac820c47107c071","placeholder":"​","style":"IPY_MODEL_a9f4417f49654c958b39bc7d95052e4c","value":" 112/112 [00:00&lt;00:00, 3.08kB/s]"}},"6717201a04084dea97539e9961209384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fca86c801b87418da6d750d50c83b1fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4228ef3961540e5bdbb5ba0a9fa9497":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcc99fe5dbf44770b5bc1be05e414638":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33f5a64520eb429f856b11918d78b901":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c729ea16a654ccfaac820c47107c071":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9f4417f49654c958b39bc7d95052e4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2baf3ed32fe4f58ac2e60bdfd59a802":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a71eba2843954958b69bec2f4378572c","IPY_MODEL_7af33cf79e364c6cb7d6a240919e7125","IPY_MODEL_4fe5a07bd98b429fad97e446838eff39"],"layout":"IPY_MODEL_46e346b7b5eb48158fd6d104dabc3b3e"}},"a71eba2843954958b69bec2f4378572c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0d072bfe9d548409aa415ee7679fe8a","placeholder":"​","style":"IPY_MODEL_46c63eb291ab4ba8a2e3b9196b346720","value":"1_Pooling/config.json: 100%"}},"7af33cf79e364c6cb7d6a240919e7125":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_183a97da33464664b1c619f629f5c816","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75cc30e52092405fbd78b63ec501a88c","value":190}},"4fe5a07bd98b429fad97e446838eff39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d308ce7c059549268ee5b90ae7d9b02d","placeholder":"​","style":"IPY_MODEL_e2e702d303944f9dace4b5887ac0d229","value":" 190/190 [00:00&lt;00:00, 3.19kB/s]"}},"46e346b7b5eb48158fd6d104dabc3b3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0d072bfe9d548409aa415ee7679fe8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46c63eb291ab4ba8a2e3b9196b346720":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"183a97da33464664b1c619f629f5c816":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75cc30e52092405fbd78b63ec501a88c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d308ce7c059549268ee5b90ae7d9b02d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2e702d303944f9dace4b5887ac0d229":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}